"""
Simple Boundary Detection Base Class for EverMemOS

This module provides a simple and extensible base class for detecting
boundaries in various types of content (conversations, emails, notes, etc.).
"""

import time
import os
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from dataclasses import dataclass
import uuid
import json, re
import asyncio
from common_utils.datetime_utils import (
    from_iso_format as dt_from_iso_format,
    from_timestamp as dt_from_timestamp,
    get_now_with_timezone,
)
from ..llm.llm_provider import LLMProvider
from api_specs.memory_types import RawDataType
from ..prompts.zh.conv_prompts import CONV_BOUNDARY_DETECTION_PROMPT

from ..prompts.eval.conv_prompts import (
    CONV_BOUNDARY_DETECTION_PROMPT as EVAL_CONV_BOUNDARY_DETECTION_PROMPT,
)
from .base_memcell_extractor import (
    MemCellExtractor,
    RawData,
    MemCell,
    StatusResult,
    MemCellExtractRequest,
)
from core.observation.logger import get_logger

logger = get_logger(__name__)


@dataclass
class BoundaryDetectionResult:
    """Boundary detection result."""

    should_end: bool
    should_wait: bool
    reasoning: str
    confidence: float
    topic_summary: Optional[str] = None


@dataclass
class ConversationMemCellExtractRequest(MemCellExtractRequest):
    pass


class ConvMemCellExtractor(MemCellExtractor):
    """
    Conversation MemCell Extractor - Responsible only for boundary detection and creating basic MemCell

    Responsibilities:
    1. Boundary detection (determine whether current MemCell should end)
    2. Create basic MemCell (including basic fields such as original_data, summary, timestamp, etc.)

    Not included:
    - Episode extraction (handled by EpisodeMemoryExtractor)
    - Foresight extraction (handled by ForesightExtractor)
    - EventLog extraction (handled by EventLogExtractor)
    - Embedding computation (handled by MemoryManager)
    """

    def __init__(self, llm_provider=LLMProvider, use_eval_prompts: bool = False):
        super().__init__(RawDataType.CONVERSATION, llm_provider)
        self.llm_provider = llm_provider
        self.use_eval_prompts = use_eval_prompts

        if use_eval_prompts:
            self.conv_boundary_detection_prompt = EVAL_CONV_BOUNDARY_DETECTION_PROMPT
        else:
            self.conv_boundary_detection_prompt = CONV_BOUNDARY_DETECTION_PROMPT

    def shutdown(self) -> None:
        """Cleanup resources."""
        pass

    def _extract_participant_ids(
        self, chat_raw_data_list: List[Dict[str, Any]]
    ) -> List[str]:
        """
        Extract all participant IDs from chat_raw_data_list

        Retrieve from the content dictionary of each element:
        1. speaker_id (speaker ID)
        2. All _id in referList (@mentioned user IDs)

        Args:
            chat_raw_data_list: List of raw chat data

        Returns:
            List[str]: List of deduplicated participant IDs
        """
        participant_ids = set()

        for raw_data in chat_raw_data_list:

            # Extract speaker_id
            if 'speaker_id' in raw_data and raw_data['speaker_id']:
                participant_ids.add(raw_data['speaker_id'])

            # Extract all IDs from referList
            if 'referList' in raw_data and raw_data['referList']:
                for refer_item in raw_data['referList']:
                    # refer_item may be a dictionary format containing _id field
                    if isinstance(refer_item, dict):
                        # Handle MongoDB ObjectId format _id
                        if '_id' in refer_item:
                            refer_id = refer_item['_id']
                            # If it's an ObjectId object, convert to string
                            if hasattr(refer_id, '__str__'):
                                participant_ids.add(str(refer_id))
                            else:
                                participant_ids.add(refer_id)
                        # Also check regular id field
                        elif 'id' in refer_item:
                            participant_ids.add(refer_item['id'])
                    # If refer_item is directly an ID string
                    elif isinstance(refer_item, str):
                        participant_ids.add(refer_item)

        return list(participant_ids)

    def _format_conversation_dicts(
        self, messages: list[dict[str, str]], include_timestamps: bool = False
    ) -> str:
        """Format conversation from message dictionaries into plain text."""
        lines = []
        for i, msg in enumerate(messages):
            content = msg.get("content", "")
            speaker_name = msg.get("speaker_name", "")
            timestamp = msg.get("timestamp", "")

            if content:
                if include_timestamps and timestamp:
                    try:
                        # Handle different types of timestamp
                        if isinstance(timestamp, datetime):
                            # If it's a datetime object, format directly
                            time_str = timestamp.strftime("%Y-%m-%d %H:%M:%S")
                            lines.append(f"[{time_str}] {speaker_name}: {content}")
                        elif isinstance(timestamp, str):
                            # If it's a string, parse and then format
                            dt = datetime.fromisoformat(
                                timestamp.replace("Z", "+00:00")
                            )
                            time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                            lines.append(f"[{time_str}] {speaker_name}: {content}")
                        else:
                            # Other types, do not include timestamp
                            lines.append(f"{speaker_name}: {content}")
                    except (ValueError, AttributeError, TypeError):
                        # Fallback if timestamp parsing fails
                        lines.append(f"{speaker_name}: {content}")
                else:
                    lines.append(f"{speaker_name}: {content}")
            else:
                print(msg)
                print(
                    f"[ConversationEpisodeBuilder] Warning: message {i} has no content"
                )
        return "\n".join(lines)

    def _calculate_time_gap(
        self,
        conversation_history: list[dict[str, str]],
        new_messages: list[dict[str, str]],
    ):
        if not conversation_history or not new_messages:
            return "No time gap information available"

        try:
            # Get the last message from history and first new message
            last_history_msg = conversation_history[-1]
            first_new_msg = new_messages[0]

            last_timestamp_str = last_history_msg.get("timestamp", "")
            first_timestamp_str = first_new_msg.get("timestamp", "")

            if not last_timestamp_str or not first_timestamp_str:
                return "No timestamp information available"

            # Parse timestamps - handle different types of timestamp
            try:
                if isinstance(last_timestamp_str, datetime):
                    last_time = last_timestamp_str
                elif isinstance(last_timestamp_str, str):
                    last_time = datetime.fromisoformat(
                        last_timestamp_str.replace("Z", "+00:00")
                    )
                else:
                    return "Invalid timestamp format for last message"

                if isinstance(first_timestamp_str, datetime):
                    first_time = first_timestamp_str
                elif isinstance(first_timestamp_str, str):
                    first_time = datetime.fromisoformat(
                        first_timestamp_str.replace("Z", "+00:00")
                    )
                else:
                    return "Invalid timestamp format for first message"
            except (ValueError, TypeError):
                return "Failed to parse timestamps"

            # Calculate time difference
            time_diff = first_time - last_time
            total_seconds = time_diff.total_seconds()

            if total_seconds < 0:
                return "Time gap: Messages appear to be out of order"
            elif total_seconds < 60:  # Less than 1 minute
                return f"Time gap: {int(total_seconds)} seconds (immediate response)"
            elif total_seconds < 3600:  # Less than 1 hour
                minutes = int(total_seconds // 60)
                return f"Time gap: {minutes} minutes (recent conversation)"
            elif total_seconds < 86400:  # Less than 1 day
                hours = int(total_seconds // 3600)
                return f"Time gap: {hours} hours (same day, but significant pause)"
            else:  # More than 1 day
                days = int(total_seconds // 86400)
                return f"Time gap: {days} days (long gap, likely new conversation)"

        except (ValueError, KeyError, AttributeError) as e:
            return f"Time gap calculation error: {str(e)}"

    async def _detect_boundary(
        self,
        conversation_history: list[dict[str, str]],
        new_messages: list[dict[str, str]],
    ) -> BoundaryDetectionResult:
        if not conversation_history:
            return BoundaryDetectionResult(
                should_end=False,
                should_wait=False,
                reasoning="First messages in conversation",
                confidence=1.0,
                topic_summary="",
            )
        history_text = self._format_conversation_dicts(
            conversation_history, include_timestamps=True
        )
        new_text = self._format_conversation_dicts(
            new_messages, include_timestamps=True
        )
        time_gap_info = self._calculate_time_gap(conversation_history, new_messages)

        print(
            f"[ConversationEpisodeBuilder] Detect boundary – history tokens: {len(history_text)} new tokens: {len(new_text)} time gap: {time_gap_info}"
        )

        prompt = self.conv_boundary_detection_prompt.format(
            conversation_history=history_text,
            new_messages=new_text,
            time_gap_info=time_gap_info,
        )
        for i in range(5):
            try:
                resp = await self.llm_provider.generate(prompt)
                print(
                    f"[ConversationEpisodeBuilder] Boundary response length: {len(resp)} chars"
                )

                # Parse JSON response from LLM boundary detection
                json_match = re.search(r"\{[^{}]*\}", resp, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                    return BoundaryDetectionResult(
                        should_end=data.get("should_end", False),
                        should_wait=data.get("should_wait", True),
                        reasoning=data.get("reasoning", "No reason provided"),
                        confidence=data.get("confidence", 1.0),
                        topic_summary=data.get("topic_summary", ""),
                    )
                else:
                    return BoundaryDetectionResult(
                        should_end=False,
                        should_wait=True,
                        reasoning="Failed to parse LLM response",
                        confidence=1.0,
                        topic_summary="",
                    )
                break
            except Exception as e:
                print('retry: ', i)
                if i == 4:
                    raise Exception("Boundary detection failed")
                continue

    async def extract_memcell(
        self, request: ConversationMemCellExtractRequest
    ) -> tuple[Optional[MemCell], Optional[StatusResult]]:
        """
        Extract basic MemCell (only contains raw data and basic fields)

        The returned MemCell only includes:
        - event_id: event ID
        - user_id_list: list of user IDs
        - original_data: raw message data
        - timestamp: timestamp
        - summary: summary
        - group_id: group ID
        - participants: participant list
        - type: data type

        Not included (to be filled by other extractors later):
        - episode: filled by EpisodeMemoryExtractor
        - foresights: filled by ForesightExtractor
        - event_log: filled by EventLogExtractor
        - extend['embedding']: filled by MemoryManager
        """
        history_message_dict_list = []
        for raw_data in request.history_raw_data_list:
            processed_data = self._data_process(raw_data)
            if processed_data is not None:  # Filter out unsupported message types
                history_message_dict_list.append(processed_data)

        # Check if the last new_raw_data is None
        if (
            request.new_raw_data_list
            and self._data_process(request.new_raw_data_list[-1]) is None
        ):
            logger.warning(
                f"[ConvMemCellExtractor] The last new_raw_data is None, skipping processing"
            )
            status_control_result = StatusResult(should_wait=True)
            return (None, status_control_result)

        new_message_dict_list = []
        for new_raw_data in request.new_raw_data_list:
            processed_data = self._data_process(new_raw_data)
            if processed_data is not None:  # Filter out unsupported message types
                new_message_dict_list.append(processed_data)

        # Check if there are valid messages to process
        if not new_message_dict_list:
            logger.warning(
                f"[ConvMemCellExtractor] No valid new messages to process (possibly all filtered out)"
            )
            status_control_result = StatusResult(should_wait=True)
            return (None, status_control_result)

        if request.smart_mask_flag:
            boundary_detection_result = await self._detect_boundary(
                conversation_history=history_message_dict_list[:-1],
                new_messages=new_message_dict_list,
            )
        else:
            boundary_detection_result = await self._detect_boundary(
                conversation_history=history_message_dict_list,
                new_messages=new_message_dict_list,
            )
        should_end = boundary_detection_result.should_end
        should_wait = boundary_detection_result.should_wait
        reason = boundary_detection_result.reasoning

        status_control_result = StatusResult(should_wait=should_wait)

        if should_end:
            # Parse timestamp
            ts_value = history_message_dict_list[-1].get("timestamp")
            timestamp = dt_from_iso_format(ts_value)
            participants = self._extract_participant_ids(history_message_dict_list)

            # Generate summary (prioritize topic summary from boundary detection)
            fallback_text = ""
            if new_message_dict_list:
                last_msg = new_message_dict_list[-1]
                if isinstance(last_msg, dict):
                    fallback_text = last_msg.get("content") or ""
                elif isinstance(last_msg, str):
                    fallback_text = last_msg
            summary_text = boundary_detection_result.topic_summary or (
                fallback_text.strip()[:200] if fallback_text else "Conversation segment"
            )
            summary_text = boundary_detection_result.topic_summary or (
                fallback_text.strip()[:200] if fallback_text else "Conversation segment"
            )

            # Create basic MemCell (without episode, foresight, event_log, embedding)
            memcell = MemCell(
                event_id=str(uuid.uuid4()),
                user_id_list=request.user_id_list,
                original_data=history_message_dict_list,
                timestamp=timestamp,
                summary=summary_text,
                group_id=request.group_id,
                participants=participants,
                type=self.raw_data_type,
            )

            logger.debug(
                f"✅ Successfully created basic MemCell: event_id={memcell.event_id}, "
                f"participants={len(participants)}, messages={len(history_message_dict_list)}"
            )

            return (memcell, status_control_result)
        elif should_wait:
            logger.debug(f"⏳ Waiting for more messages: {reason}")
        return (None, status_control_result)

    def _data_process(self, raw_data: RawData) -> Dict[str, Any]:
        """Process raw data, including message type filtering and preprocessing"""
        content = (
            raw_data.content.copy()
            if isinstance(raw_data.content, dict)
            else raw_data.content
        )

        # Get message type
        msg_type = content.get('msgType') if isinstance(content, dict) else None

        # Define supported message types and corresponding placeholders
        SUPPORTED_MSG_TYPES = {
            1: None,  # TEXT - keep original text
            2: "[Image]",  # PICTURE
            3: "[Video]",  # VIDEO
            4: "[Audio]",  # AUDIO
            5: "[File]",  # FILE - keep original text (text and file in same message)
            6: "[File]",  # FILES
        }

        if isinstance(content, dict) and msg_type is not None:
            # Check if it's a supported message type
            if msg_type not in SUPPORTED_MSG_TYPES:
                # Unsupported message type, skip directly (returning None will be handled at upper level)
                logger.warning(
                    f"[ConvMemCellExtractor] Skipping unsupported message type: {msg_type}"
                )
                return None

            # Preprocess non-text messages
            placeholder = SUPPORTED_MSG_TYPES[msg_type]
            if placeholder is not None:
                # Replace message content with placeholder
                content = content.copy()
                content['content'] = placeholder
                logger.debug(
                    f"[ConvMemCellExtractor] Message type {msg_type} converted to placeholder: {placeholder}"
                )

        return content
