"""
Redisæ¶ˆæ¯åˆ†ç»„é˜Ÿåˆ—ç®¡ç†å™¨BSONåºåˆ—åŒ–å¢å¼ºæµ‹è¯•

æµ‹è¯•è¦†ç›–ï¼š
1. BSONåºåˆ—åŒ–æ”¯æŒ
2. JSONåºåˆ—åŒ–æ”¯æŒ
3. åºåˆ—åŒ–æ¨¡å¼éš”ç¦»æ€§
4. è‡ªå®šä¹‰RedisGroupQueueItemæ”¯æŒ
5. äºŒè¿›åˆ¶æ•°æ®å®Œæ•´æ€§
6. æ‰€æœ‰ç®¡ç†å™¨æ–¹æ³•çš„BSONå…¼å®¹æ€§
7. Luaè„šæœ¬è¿”å›å€¼çš„äºŒè¿›åˆ¶å¤„ç†
"""

import asyncio
import sys
import os
import time
import traceback
import base64
import json

# Mockä¾èµ–æ¨¡å—
from unittest.mock import MagicMock

sys.modules['tanka_ai_toolkit'] = MagicMock()
sys.modules['tanka_ai_toolkit.utils'] = MagicMock()
sys.modules['tanka_ai_toolkit.utils.log_tools'] = MagicMock()
sys.modules['tanka_ai_toolkit.utils.log_tools.tanka_log'] = MagicMock()

try:
    from core.queue.redis_group_queue.redis_group_queue_item import (
        SimpleQueueItem,
        SerializationMode,
    )
    from core.queue.redis_group_queue.redis_msg_group_queue_manager import (
        RedisGroupQueueManager,
        ShutdownMode,
    )
    from core.queue.redis_group_queue.redis_msg_group_queue_manager_factory import (
        RedisGroupQueueManagerFactory,
        RedisGroupQueueConfig,
    )
    from core.di.utils import get_bean_by_type
    from component.redis_provider import RedisProvider

    IMPORTS_AVAILABLE = True
    print("âœ… æˆåŠŸå¯¼å…¥æ ¸å¿ƒæ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    IMPORTS_AVAILABLE = False
    sys.exit(1)


# ==================== è‡ªå®šä¹‰é˜Ÿåˆ—é¡¹ç±» ====================


class CustomQueueItem(SimpleQueueItem):
    """è‡ªå®šä¹‰é˜Ÿåˆ—é¡¹ï¼Œç”¨äºæµ‹è¯•item_classå‚æ•°"""

    def __init__(self, data, item_type, priority=0, custom_field="default"):
        super().__init__(data, item_type)
        self.priority = priority
        self.custom_field = custom_field

    def to_dict(self):
        """é‡å†™to_dictæ–¹æ³•ï¼ŒåŒ…å«è‡ªå®šä¹‰å­—æ®µ"""
        base_dict = super().to_dict()
        base_dict.update({"priority": self.priority, "custom_field": self.custom_field})
        return base_dict

    @classmethod
    def from_json_str(cls, json_str: str):
        """é‡å†™from_json_stræ–¹æ³•"""
        try:
            json_dict = json.loads(json_str)
            return cls(
                data=json_dict["data"],
                item_type=json_dict.get("item_type", "custom"),
                priority=json_dict.get("priority", 0),
                custom_field=json_dict.get("custom_field", "default"),
            )
        except (json.JSONDecodeError, KeyError) as e:
            raise ValueError(f"æ— æ•ˆçš„JSONæ•°æ®: {e}") from e

    @classmethod
    def from_bson_bytes(cls, bson_bytes: bytes):
        """é‡å†™from_bson_bytesæ–¹æ³•"""
        try:
            import bson

            data = bson.decode(bson_bytes)
            return cls(
                data=data["data"],
                item_type=data.get("item_type", "custom"),
                priority=data.get("priority", 0),
                custom_field=data.get("custom_field", "default"),
            )
        except Exception as e:
            raise ValueError(f"æ— æ•ˆçš„BSONæ•°æ®: {e}") from e


# ==================== åŸºç¡€åºåˆ—åŒ–æµ‹è¯• ====================


async def test_bson_serialization_support(manager_factory):
    """æµ‹è¯•BSONåºåˆ—åŒ–æ”¯æŒ"""

    # åˆ›å»ºä½¿ç”¨BSONåºåˆ—åŒ–çš„ç®¡ç†å™¨
    bson_manager = await manager_factory.get_manager_with_config(
        key_prefix="bson_test_manager",
        serialization_mode=SerializationMode.BSON,
        auto_start=False,
    )

    print("\n=== æµ‹è¯•BSONåºåˆ—åŒ–æ¨¡å¼ ===")

    # åˆ›å»ºåŒ…å«å¤æ‚æ•°æ®çš„æ¶ˆæ¯
    complex_message = SimpleQueueItem(
        data={
            "user_id": 12345,
            "content": "æµ‹è¯•BSONåºåˆ—åŒ–",
            "metadata": {
                "timestamp": time.time(),
                "tags": ["test", "bson", "serialization"],
                "nested": {"level": 2, "value": 3.14159},
            },
            "binary_data": b"some binary content".hex(),  # æ¨¡æ‹ŸäºŒè¿›åˆ¶æ•°æ®
        },
        item_type="bson_test",
    )

    # æŠ•é€’æ¶ˆæ¯
    success = await bson_manager.deliver_message("bson_group", complex_message)
    assert success, "BSONæ¶ˆæ¯æŠ•é€’åº”è¯¥æˆåŠŸ"

    # è·å–æ¶ˆæ¯
    messages = await bson_manager.get_messages(score_threshold=0)
    assert len(messages) == 1, "åº”è¯¥è·å–åˆ°1æ¡BSONæ¶ˆæ¯"

    retrieved_message = messages[0]
    assert retrieved_message.data["user_id"] == 12345
    assert retrieved_message.data["content"] == "æµ‹è¯•BSONåºåˆ—åŒ–"
    assert retrieved_message.data["metadata"]["tags"] == [
        "test",
        "bson",
        "serialization",
    ]
    assert retrieved_message.data["metadata"]["nested"]["level"] == 2
    assert retrieved_message.item_type == "bson_test"

    print("âœ… BSONåºåˆ—åŒ–æµ‹è¯•é€šè¿‡")


# ==================== ç®¡ç†å™¨æ–¹æ³•å…¨è¦†ç›–æµ‹è¯• ====================


async def test_consumer_management_methods_bson(manager_factory):
    """æµ‹è¯•æ¶ˆè´¹è€…ç®¡ç†æ–¹æ³•åœ¨BSONæ¨¡å¼ä¸‹çš„å…¼å®¹æ€§"""

    bson_manager = await manager_factory.get_manager_with_config(
        key_prefix="consumer_mgmt_bson",
        serialization_mode=SerializationMode.BSON,
        auto_start=False,
    )

    print("\n=== æµ‹è¯•æ¶ˆè´¹è€…ç®¡ç†æ–¹æ³•BSONå…¼å®¹æ€§ ===")

    # æµ‹è¯• join_consumer
    owner_count, assigned_partitions = await bson_manager.join_consumer()
    assert owner_count >= 1, "åŠ å…¥æ¶ˆè´¹è€…ååº”è¯¥æœ‰è‡³å°‘1ä¸ªowner"
    assert isinstance(assigned_partitions, dict), "åˆ†é…ç»“æœåº”è¯¥æ˜¯å­—å…¸"
    print(
        f"âœ… join_consumer: owner_count={owner_count}, partitions={len(assigned_partitions)}"
    )

    # æµ‹è¯• keepalive_consumer
    keepalive_success = await bson_manager.keepalive_consumer(bson_manager.owner_id)
    assert keepalive_success, "æ¶ˆè´¹è€…ä¿æ´»åº”è¯¥æˆåŠŸ"
    print("âœ… keepalive_consumer æˆåŠŸ")

    # æµ‹è¯• rebalance_partitions
    rebalance_owner_count, rebalance_partitions = (
        await bson_manager.rebalance_partitions()
    )
    assert rebalance_owner_count >= 1, "rebalanceååº”è¯¥æœ‰è‡³å°‘1ä¸ªowner"
    assert isinstance(rebalance_partitions, dict), "rebalanceç»“æœåº”è¯¥æ˜¯å­—å…¸"
    print(f"âœ… rebalance_partitions: owner_count={rebalance_owner_count}")

    # æµ‹è¯• cleanup_inactive_owners
    cleaned_count, remaining_count, cleanup_partitions = (
        await bson_manager.cleanup_inactive_owners()
    )
    assert cleaned_count >= 0, "æ¸…ç†æ•°é‡åº”è¯¥>=0"
    assert remaining_count >= 0, "å‰©ä½™æ•°é‡åº”è¯¥>=0"
    assert isinstance(cleanup_partitions, dict), "æ¸…ç†ç»“æœåº”è¯¥æ˜¯å­—å…¸"
    print(
        f"âœ… cleanup_inactive_owners: cleaned={cleaned_count}, remaining={remaining_count}"
    )

    # æµ‹è¯• exit_consumer
    exit_owner_count, exit_partitions = await bson_manager.exit_consumer()
    assert exit_owner_count >= 0, "é€€å‡ºåowneræ•°é‡åº”è¯¥>=0"
    assert isinstance(exit_partitions, dict), "é€€å‡ºç»“æœåº”è¯¥æ˜¯å­—å…¸"
    print(f"âœ… exit_consumer: remaining_owners={exit_owner_count}")

    print("âœ… æ¶ˆè´¹è€…ç®¡ç†æ–¹æ³•BSONå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


async def test_stats_methods_bson(manager_factory):
    """æµ‹è¯•ç»Ÿè®¡æ–¹æ³•åœ¨BSONæ¨¡å¼ä¸‹çš„å…¼å®¹æ€§"""

    bson_manager = await manager_factory.get_manager_with_config(
        key_prefix="stats_bson",
        serialization_mode=SerializationMode.BSON,
        auto_start=False,
    )

    print("\n=== æµ‹è¯•ç»Ÿè®¡æ–¹æ³•BSONå…¼å®¹æ€§ ===")

    # å…ˆæŠ•é€’ä¸€äº›æ¶ˆæ¯
    await bson_manager.join_consumer()
    for i in range(3):
        message = SimpleQueueItem(
            data={"index": i, "content": f"ç»Ÿè®¡æµ‹è¯•æ¶ˆæ¯{i}"}, item_type="stats_test"
        )
        await bson_manager.deliver_message(f"stats_group_{i}", message)

    # æµ‹è¯• get_stats (ç®¡ç†å™¨çº§åˆ«)
    manager_stats = await bson_manager.get_stats()
    assert isinstance(manager_stats, dict), "ç®¡ç†å™¨ç»Ÿè®¡åº”è¯¥æ˜¯å­—å…¸"
    assert "total_current_messages" in manager_stats, "åº”è¯¥åŒ…å«æ€»æ¶ˆæ¯æ•°"
    assert "total_queues" in manager_stats, "åº”è¯¥åŒ…å«é˜Ÿåˆ—æ•°"
    print(
        f"âœ… get_stats (manager): messages={manager_stats.get('total_current_messages', 0)}"
    )

    # æµ‹è¯• get_stats (é˜Ÿåˆ—çº§åˆ«)
    queue_stats = await bson_manager.get_stats(group_key="stats_group_0")
    assert isinstance(queue_stats, dict), "é˜Ÿåˆ—ç»Ÿè®¡åº”è¯¥æ˜¯å­—å…¸"
    assert "current_size" in queue_stats, "åº”è¯¥åŒ…å«å½“å‰å¤§å°"
    print(f"âœ… get_stats (queue): size={queue_stats.get('current_size', 0)}")

    # æµ‹è¯• get_stats (åŒ…å«æ‰€æœ‰åˆ†åŒº)
    all_partitions_stats = await bson_manager.get_stats(
        include_all_partitions=True,
        include_partition_details=True,
        include_consumer_info=True,
    )
    assert isinstance(all_partitions_stats, dict), "å…¨åˆ†åŒºç»Ÿè®¡åº”è¯¥æ˜¯å­—å…¸"
    assert "partitions" in all_partitions_stats, "åº”è¯¥åŒ…å«åˆ†åŒºä¿¡æ¯"
    assert "active_consumers" in all_partitions_stats, "åº”è¯¥åŒ…å«æ¶ˆè´¹è€…ä¿¡æ¯"
    print(
        f"âœ… get_stats (all partitions): partitions={len(all_partitions_stats.get('partitions', []))}"
    )

    # æµ‹è¯•å…¼å®¹æ€§æ–¹æ³•
    queue_stats_compat = await bson_manager.get_queue_stats("stats_group_0")
    assert queue_stats_compat is not None, "å…¼å®¹æ€§é˜Ÿåˆ—ç»Ÿè®¡åº”è¯¥ä¸ä¸ºç©º"

    manager_stats_compat = await bson_manager.get_manager_stats()
    assert isinstance(manager_stats_compat, dict), "å…¼å®¹æ€§ç®¡ç†å™¨ç»Ÿè®¡åº”è¯¥æ˜¯å­—å…¸"

    print("âœ… ç»Ÿè®¡æ–¹æ³•BSONå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


async def test_message_operations_bson(manager_factory):
    """æµ‹è¯•æ¶ˆæ¯æ“ä½œåœ¨BSONæ¨¡å¼ä¸‹çš„å…¼å®¹æ€§"""

    bson_manager = await manager_factory.get_manager_with_config(
        key_prefix="msg_ops_bson",
        serialization_mode=SerializationMode.BSON,
        auto_start=False,
    )

    print("\n=== æµ‹è¯•æ¶ˆæ¯æ“ä½œBSONå…¼å®¹æ€§ ===")

    await bson_manager.join_consumer()

    # æµ‹è¯• deliver_message ä¸å¤æ‚æ•°æ®
    complex_data = {
        "text": "å¤æ‚æ¶ˆæ¯æµ‹è¯•",
        "numbers": [1, 2, 3.14, -5],
        "nested": {"bool_val": True, "null_val": None, "unicode": "ä¸­æ–‡æµ‹è¯•ğŸš€"},
        "binary_encoded": base64.b64encode(b"binary data \x00\x01\x02").decode(),
    }

    message = SimpleQueueItem(data=complex_data, item_type="complex_bson")
    success = await bson_manager.deliver_message("complex_group", message)
    assert success, "å¤æ‚æ¶ˆæ¯æŠ•é€’åº”è¯¥æˆåŠŸ"
    print("âœ… deliver_message å¤æ‚æ•°æ®æŠ•é€’æˆåŠŸ")

    # æµ‹è¯• get_messages ä¸ä¸åŒå‚æ•°
    # æµ‹è¯•åŸºæœ¬è·å–
    messages = await bson_manager.get_messages(score_threshold=0)
    assert len(messages) >= 1, "åº”è¯¥è·å–åˆ°è‡³å°‘1æ¡æ¶ˆæ¯"
    retrieved = messages[0]
    assert retrieved.data["text"] == "å¤æ‚æ¶ˆæ¯æµ‹è¯•"
    assert retrieved.data["nested"]["unicode"] == "ä¸­æ–‡æµ‹è¯•ğŸš€"
    print("âœ… get_messages åŸºæœ¬è·å–æˆåŠŸ")

    # æµ‹è¯•å¸¦current_scoreå‚æ•°çš„è·å–
    current_time_ms = int(time.time() * 1000)
    messages_with_score = await bson_manager.get_messages(
        score_threshold=1000, current_score=current_time_ms  # 1ç§’é˜ˆå€¼
    )
    # è¿™é‡Œå¯èƒ½è·å–åˆ°æ¶ˆæ¯ä¹Ÿå¯èƒ½ä¸è·å–åˆ°ï¼Œå–å†³äºæ—¶é—´å·®
    print(
        f"âœ… get_messages å¸¦current_scoreå‚æ•°: è·å–åˆ°{len(messages_with_score)}æ¡æ¶ˆæ¯"
    )

    # æµ‹è¯•æŒ‡å®šowner_idçš„è·å–
    messages_with_owner = await bson_manager.get_messages(
        score_threshold=0, owner_id=bson_manager.owner_id
    )
    print(f"âœ… get_messages æŒ‡å®šowner_id: è·å–åˆ°{len(messages_with_owner)}æ¡æ¶ˆæ¯")

    print("âœ… æ¶ˆæ¯æ“ä½œBSONå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


async def test_lifecycle_management_bson(manager_factory):
    """æµ‹è¯•ç”Ÿå‘½å‘¨æœŸç®¡ç†åœ¨BSONæ¨¡å¼ä¸‹çš„å…¼å®¹æ€§"""

    bson_manager = await manager_factory.get_manager_with_config(
        key_prefix="lifecycle_bson",
        serialization_mode=SerializationMode.BSON,
        auto_start=False,  # æ‰‹åŠ¨æ§åˆ¶å¯åŠ¨
    )

    print("\n=== æµ‹è¯•ç”Ÿå‘½å‘¨æœŸç®¡ç†BSONå…¼å®¹æ€§ ===")

    # æµ‹è¯•çŠ¶æ€è·å–
    from core.queue.redis_group_queue.redis_msg_group_queue_manager import ManagerState

    initial_state = bson_manager.get_state()
    assert (
        initial_state == ManagerState.CREATED
    ), f"åˆå§‹çŠ¶æ€åº”è¯¥æ˜¯CREATEDï¼Œå®é™…æ˜¯{initial_state}"
    print("âœ… get_state åˆå§‹çŠ¶æ€æ­£ç¡®")

    # æµ‹è¯•å¯åŠ¨
    await bson_manager.start()
    started_state = bson_manager.get_state()
    assert (
        started_state == ManagerState.STARTED
    ), f"å¯åŠ¨åçŠ¶æ€åº”è¯¥æ˜¯STARTEDï¼Œå®é™…æ˜¯{started_state}"
    print("âœ… start å¯åŠ¨æˆåŠŸ")

    # æµ‹è¯•å®šæœŸä»»åŠ¡å¯åŠ¨
    await bson_manager.start_periodic_tasks()  # åº”è¯¥æ˜¯å¹‚ç­‰çš„
    print("âœ… start_periodic_tasks å¹‚ç­‰è°ƒç”¨æˆåŠŸ")

    # æµ‹è¯•è½¯æ€§å…³é—­ï¼ˆåº”è¯¥å¤±è´¥ï¼Œå› ä¸ºå¯èƒ½æœ‰æ¶ˆæ¯ï¼‰
    soft_shutdown_result = await bson_manager.shutdown(ShutdownMode.SOFT)
    print(f"âœ… shutdown SOFTæ¨¡å¼: ç»“æœ={soft_shutdown_result}")

    # æµ‹è¯•ç¡¬æ€§å…³é—­
    hard_shutdown_result = await bson_manager.shutdown(ShutdownMode.HARD)
    assert hard_shutdown_result, "ç¡¬æ€§å…³é—­åº”è¯¥æˆåŠŸ"
    shutdown_state = bson_manager.get_state()
    assert (
        shutdown_state == ManagerState.SHUTDOWN
    ), f"å…³é—­åçŠ¶æ€åº”è¯¥æ˜¯SHUTDOWNï¼Œå®é™…æ˜¯{shutdown_state}"
    print("âœ… shutdown HARDæ¨¡å¼æˆåŠŸ")

    print("âœ… ç”Ÿå‘½å‘¨æœŸç®¡ç†BSONå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


async def test_force_cleanup_bson(manager_factory):
    """æµ‹è¯•å¼ºåˆ¶æ¸…ç†åœ¨BSONæ¨¡å¼ä¸‹çš„å…¼å®¹æ€§"""

    bson_manager = await manager_factory.get_manager_with_config(
        key_prefix="force_cleanup_bson",
        serialization_mode=SerializationMode.BSON,
        auto_start=False,
    )

    print("\n=== æµ‹è¯•å¼ºåˆ¶æ¸…ç†BSONå…¼å®¹æ€§ ===")

    # å…ˆåŠ å…¥ä¸€äº›æ¶ˆè´¹è€…
    await bson_manager.join_consumer()
    await bson_manager.join_consumer("test_owner_1")
    await bson_manager.join_consumer("test_owner_2")

    # æ£€æŸ¥æ¶ˆè´¹è€…æ•°é‡
    stats_before = await bson_manager.get_stats(include_consumer_info=True)
    consumers_before = len(stats_before.get("active_consumers", []))
    print(f"æ¸…ç†å‰æ¶ˆè´¹è€…æ•°é‡: {consumers_before}")

    # æµ‹è¯•å¼ºåˆ¶æ¸…ç†
    cleaned_count = await bson_manager.force_cleanup_and_reset()
    assert cleaned_count >= 0, "æ¸…ç†æ•°é‡åº”è¯¥>=0"
    print(f"âœ… force_cleanup_and_reset: æ¸…ç†äº†{cleaned_count}ä¸ªæ¶ˆè´¹è€…")

    # æ£€æŸ¥æ¸…ç†åçŠ¶æ€
    stats_after = await bson_manager.get_stats(include_consumer_info=True)
    consumers_after = len(stats_after.get("active_consumers", []))
    print(f"æ¸…ç†åæ¶ˆè´¹è€…æ•°é‡: {consumers_after}")

    print("âœ… å¼ºåˆ¶æ¸…ç†BSONå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


async def test_custom_item_class_bson(manager_factory):
    """æµ‹è¯•è‡ªå®šä¹‰item_classåœ¨BSONæ¨¡å¼ä¸‹çš„å…¼å®¹æ€§"""

    custom_manager = await manager_factory.get_manager_with_config(
        key_prefix="custom_bson",
        serialization_mode=SerializationMode.BSON,
        item_class=CustomQueueItem,
        auto_start=False,
    )

    print("\n=== æµ‹è¯•è‡ªå®šä¹‰item_class BSONå…¼å®¹æ€§ ===")

    await custom_manager.join_consumer()

    # åˆ›å»ºè‡ªå®šä¹‰æ¶ˆæ¯
    custom_message = CustomQueueItem(
        data={"content": "è‡ªå®šä¹‰BSONæµ‹è¯•", "value": 999},
        item_type="custom_bson_test",
        priority=10,
        custom_field="bson_custom_value",
    )

    # æŠ•é€’å’Œè·å–
    success = await custom_manager.deliver_message("custom_bson_group", custom_message)
    assert success, "è‡ªå®šä¹‰BSONæ¶ˆæ¯æŠ•é€’åº”è¯¥æˆåŠŸ"

    messages = await custom_manager.get_messages(score_threshold=0)
    assert len(messages) == 1, "åº”è¯¥è·å–åˆ°1æ¡è‡ªå®šä¹‰BSONæ¶ˆæ¯"

    retrieved = messages[0]
    assert isinstance(retrieved, CustomQueueItem), "è·å–çš„æ¶ˆæ¯åº”è¯¥æ˜¯CustomQueueItemç±»å‹"
    assert retrieved.priority == 10, "è‡ªå®šä¹‰å­—æ®µpriorityåº”è¯¥æ­£ç¡®"
    assert (
        retrieved.custom_field == "bson_custom_value"
    ), "è‡ªå®šä¹‰å­—æ®µcustom_fieldåº”è¯¥æ­£ç¡®"
    assert retrieved.data["content"] == "è‡ªå®šä¹‰BSONæµ‹è¯•"

    print("âœ… è‡ªå®šä¹‰item_class BSONå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


async def test_binary_data_integrity_bson(manager_factory):
    """æµ‹è¯•äºŒè¿›åˆ¶æ•°æ®åœ¨BSONæ¨¡å¼ä¸‹çš„å®Œæ•´æ€§"""

    bson_manager = await manager_factory.get_manager_with_config(
        key_prefix="binary_integrity",
        serialization_mode=SerializationMode.BSON,
        auto_start=False,
    )

    print("\n=== æµ‹è¯•äºŒè¿›åˆ¶æ•°æ®å®Œæ•´æ€§ ===")

    await bson_manager.join_consumer()

    # åˆ›å»ºåŒ…å«å„ç§äºŒè¿›åˆ¶æ•°æ®çš„æ¶ˆæ¯
    test_binary_data = [
        b"",  # ç©ºäºŒè¿›åˆ¶
        b"\x00",  # å•ä¸ªnullå­—èŠ‚
        b"\x00\x01\x02\x03\xff\xfe\xfd",  # æ··åˆå­—èŠ‚
        "Hello, ä¸–ç•Œ! ğŸŒ".encode('utf-8'),  # UTF-8ç¼–ç çš„æ–‡æœ¬
        bytes(range(256)),  # æ‰€æœ‰å¯èƒ½çš„å­—èŠ‚å€¼
    ]

    for i, binary_data in enumerate(test_binary_data):
        encoded_data = base64.b64encode(binary_data).decode('utf-8')

        message = SimpleQueueItem(
            data={
                "binary_field": encoded_data,
                "original_length": len(binary_data),
                "test_index": i,
            },
            item_type=f"binary_test_{i}",
        )

        success = await bson_manager.deliver_message(f"binary_group_{i}", message)
        assert success, f"äºŒè¿›åˆ¶æ¶ˆæ¯{i}æŠ•é€’åº”è¯¥æˆåŠŸ"

    # è·å–æ‰€æœ‰æ¶ˆæ¯å¹¶éªŒè¯å®Œæ•´æ€§
    for i in range(len(test_binary_data)):
        messages = await bson_manager.get_messages(score_threshold=0)
        if messages:
            retrieved = messages[0]

            # è§£ç å¹¶éªŒè¯
            decoded_data = base64.b64decode(retrieved.data["binary_field"])
            original_data = test_binary_data[retrieved.data["test_index"]]

            assert decoded_data == original_data, f"äºŒè¿›åˆ¶æ•°æ®{i}å®Œæ•´æ€§éªŒè¯å¤±è´¥"
            assert (
                len(decoded_data) == retrieved.data["original_length"]
            ), f"äºŒè¿›åˆ¶æ•°æ®{i}é•¿åº¦ä¸åŒ¹é…"

    print("âœ… äºŒè¿›åˆ¶æ•°æ®å®Œæ•´æ€§æµ‹è¯•é€šè¿‡")


async def test_lua_script_return_compatibility(manager_factory):
    """æµ‹è¯•Luaè„šæœ¬è¿”å›å€¼åœ¨BSONæ¨¡å¼ä¸‹çš„å…¼å®¹æ€§"""

    bson_manager = await manager_factory.get_manager_with_config(
        key_prefix="lua_compat",
        serialization_mode=SerializationMode.BSON,
        auto_start=False,
    )

    print("\n=== æµ‹è¯•Luaè„šæœ¬è¿”å›å€¼å…¼å®¹æ€§ ===")

    # æµ‹è¯•å„ç§ä¼šè°ƒç”¨Luaè„šæœ¬çš„æ“ä½œï¼Œç¡®ä¿è¿”å›å€¼æ­£ç¡®å¤„ç†

    # 1. æµ‹è¯•enqueueè„šæœ¬è¿”å›å€¼å¤„ç†
    message = SimpleQueueItem(data={"test": "lua_compat"}, item_type="lua_test")
    success = await bson_manager.deliver_message("lua_group", message)
    assert success, "enqueueè„šæœ¬åº”è¯¥æ­£ç¡®å¤„ç†è¿”å›å€¼"
    print("âœ… enqueueè„šæœ¬è¿”å›å€¼å¤„ç†æ­£ç¡®")

    # 2. æµ‹è¯•join_consumerè„šæœ¬è¿”å›å€¼å¤„ç†
    owner_count, partitions = await bson_manager.join_consumer()
    assert isinstance(owner_count, int), "join_consumeråº”è¯¥è¿”å›æ•´æ•°owner_count"
    assert isinstance(partitions, dict), "join_consumeråº”è¯¥è¿”å›å­—å…¸partitions"
    for owner_id, partition_list in partitions.items():
        assert isinstance(owner_id, str), f"owner_idåº”è¯¥æ˜¯å­—ç¬¦ä¸²: {owner_id}"
        assert isinstance(
            partition_list, list
        ), f"partition_liståº”è¯¥æ˜¯åˆ—è¡¨: {partition_list}"
        for partition in partition_list:
            assert isinstance(partition, str), f"partitionåº”è¯¥æ˜¯å­—ç¬¦ä¸²: {partition}"
    print("âœ… join_consumerè„šæœ¬è¿”å›å€¼å¤„ç†æ­£ç¡®")

    # 3. æµ‹è¯•get_messagesè„šæœ¬è¿”å›å€¼å¤„ç†
    messages = await bson_manager.get_messages(score_threshold=0)
    assert isinstance(messages, list), "get_messagesåº”è¯¥è¿”å›åˆ—è¡¨"
    if messages:
        assert isinstance(messages[0], SimpleQueueItem), "æ¶ˆæ¯åº”è¯¥æ­£ç¡®ååºåˆ—åŒ–"
    print("âœ… get_messagesè„šæœ¬è¿”å›å€¼å¤„ç†æ­£ç¡®")

    # 4. æµ‹è¯•statsè„šæœ¬è¿”å›å€¼å¤„ç†
    stats = await bson_manager.get_stats()
    assert isinstance(stats, dict), "get_statsåº”è¯¥è¿”å›å­—å…¸"
    for key, value in stats.items():
        assert isinstance(key, str), f"ç»Ÿè®¡é”®åº”è¯¥æ˜¯å­—ç¬¦ä¸²: {key}"
    print("âœ… statsè„šæœ¬è¿”å›å€¼å¤„ç†æ­£ç¡®")

    # 5. æµ‹è¯•cleanupè„šæœ¬è¿”å›å€¼å¤„ç†
    cleaned, remaining, cleanup_partitions = (
        await bson_manager.cleanup_inactive_owners()
    )
    assert isinstance(cleaned, int), "cleanupåº”è¯¥è¿”å›æ•´æ•°cleaned_count"
    assert isinstance(remaining, int), "cleanupåº”è¯¥è¿”å›æ•´æ•°remaining_count"
    assert isinstance(cleanup_partitions, dict), "cleanupåº”è¯¥è¿”å›å­—å…¸partitions"
    print("âœ… cleanupè„šæœ¬è¿”å›å€¼å¤„ç†æ­£ç¡®")

    print("âœ… Luaè„šæœ¬è¿”å›å€¼å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


# ==================== è¿è¡Œæµ‹è¯• ====================


async def run_enhanced_bson_tests():
    """è¿è¡Œå¢å¼ºçš„BSONåºåˆ—åŒ–æµ‹è¯•"""
    print("å¼€å§‹è¿è¡ŒRedisæ¶ˆæ¯åˆ†ç»„é˜Ÿåˆ—ç®¡ç†å™¨å¢å¼ºBSONåºåˆ—åŒ–æµ‹è¯•...")

    try:
        # è·å–ç®¡ç†å™¨å·¥å‚å®ä¾‹
        manager_factory = get_bean_by_type(RedisGroupQueueManagerFactory)
        redis_provider = get_bean_by_type(RedisProvider)

    except Exception as e:
        print(f"âŒ è·å–ä¾èµ–å¤±è´¥: {e}")
        return

    # å®šä¹‰æ‰€æœ‰æµ‹è¯•å‡½æ•°
    tests = [
        # åŸºç¡€åºåˆ—åŒ–æµ‹è¯•
        test_bson_serialization_support,
        # ç®¡ç†å™¨æ–¹æ³•å…¨è¦†ç›–æµ‹è¯•
        test_consumer_management_methods_bson,
        test_stats_methods_bson,
        test_message_operations_bson,
        test_lifecycle_management_bson,
        test_force_cleanup_bson,
        # è‡ªå®šä¹‰ç±»å’ŒäºŒè¿›åˆ¶æ•°æ®æµ‹è¯•
        test_custom_item_class_bson,
        test_binary_data_integrity_bson,
        # Luaè„šæœ¬å…¼å®¹æ€§æµ‹è¯•
        test_lua_script_return_compatibility,
    ]

    passed = 0
    failed = 0

    # è·å–Rediså®¢æˆ·ç«¯ç”¨äºæ¸…ç†
    redis_client = await redis_provider.get_named_client(
        "default", decode_responses=True
    )

    # å¯åŠ¨æ—¶æ¸…ç†æ•°æ®åº“
    try:
        await redis_client.flushdb()
        print("ğŸ§¹ å¯åŠ¨æ—¶Redisæ•°æ®åº“å·²æ¸…ç†")
    except Exception as e:
        print(f"âš ï¸ å¯åŠ¨æ—¶æ¸…ç†Redisæ•°æ®åº“å¤±è´¥: {e}")
        return

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    for test_func in tests:
        print(f"\n{'='*60}")
        print(f"è¿è¡Œæµ‹è¯•: {test_func.__name__}")
        print(f"{'='*60}")

        # æµ‹è¯•å‰æ¸…ç†Redisæ•°æ®åº“
        try:
            await redis_client.flushdb()
            print("ğŸ§¹ Redisæ•°æ®åº“å·²æ¸…ç†")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†Redisæ•°æ®åº“å¤±è´¥: {e}")

        try:
            await test_func(manager_factory)
            print(f"âœ… {test_func.__name__} æµ‹è¯•é€šè¿‡")
            passed += 1
        except AssertionError as e:
            print(f"âŒ {test_func.__name__} æµ‹è¯•å¤±è´¥: {str(e)}")
            failed += 1
            traceback.print_exc()
            break  # é‡åˆ°å¤±è´¥å°±åœæ­¢
        except Exception as e:
            print(f"âŒ {test_func.__name__} æµ‹è¯•å‡ºé”™: {str(e)}")
            failed += 1
            traceback.print_exc()
            break  # é‡åˆ°é”™è¯¯å°±åœæ­¢

        # æµ‹è¯•ååœæ­¢æ‰€æœ‰ç®¡ç†å™¨
        try:
            await manager_factory.stop_all_managers()
            print("ğŸ”Œ æµ‹è¯•åæ‰€æœ‰ç®¡ç†å™¨å·²åœæ­¢")
        except Exception as e:
            print(f"âš ï¸ åœæ­¢ç®¡ç†å™¨å¤±è´¥: {e}")

        # çŸ­æš‚ç­‰å¾…
        await asyncio.sleep(0.1)

    print(f"\n{'='*60}")
    print(f"å¢å¼ºBSONæµ‹è¯•ç»“æœ: {passed} é€šè¿‡, {failed} å¤±è´¥")
    print(f"{'='*60}")

    # æ¸…ç†æ‰€æœ‰ç®¡ç†å™¨
    await manager_factory.stop_all_managers()
    print("ğŸ”Œ æ‰€æœ‰ç®¡ç†å™¨å·²åœæ­¢")

    # æœ€ç»ˆæ¸…ç†Redisæ•°æ®åº“
    try:
        await redis_client.flushdb()
        print("ğŸ§¹ æœ€ç»ˆRedisæ•°æ®åº“æ¸…ç†å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ æœ€ç»ˆæ¸…ç†Redisæ•°æ®åº“å¤±è´¥: {e}")
    finally:
        await redis_client.close()
        print("ğŸ”Œ Redisè¿æ¥å·²å…³é—­")


if __name__ == "__main__":
    asyncio.run(run_enhanced_bson_tests())
