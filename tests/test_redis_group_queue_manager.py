"""
Redisæ¶ˆæ¯åˆ†ç»„é˜Ÿåˆ—ç®¡ç†å™¨ç»¼åˆæµ‹è¯•

æµ‹è¯•è¦†ç›–ï¼š
1. åŸºæœ¬åŠŸèƒ½æµ‹è¯•ï¼ˆæŠ•é€’ã€è·å–ã€ç»Ÿè®¡ï¼‰
2. åˆ†ç»„è·¯ç”±æµ‹è¯•
3. Scoreé˜ˆå€¼æµ‹è¯•
4. æ¶ˆè´¹è€…ç®¡ç†æµ‹è¯•ï¼ˆåŠ å…¥ã€é€€å‡ºã€ä¿æ´»ï¼‰
5. Rebalanceæµ‹è¯•
6. æ¸…ç†åŠŸèƒ½æµ‹è¯•
7. è¾¹è§’æƒ…å†µæµ‹è¯•
8. å¹¶å‘æµ‹è¯•
"""

import asyncio
import sys
import time
import traceback

# å°è¯•å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨mock
try:
    # å…ˆå°è¯• Mock tanka_ai_toolkit ä¾èµ–
    from unittest.mock import MagicMock

    # Mock tanka_ai_toolkit æ¨¡å—
    sys.modules['tanka_ai_toolkit'] = MagicMock()
    sys.modules['tanka_ai_toolkit.utils'] = MagicMock()
    sys.modules['tanka_ai_toolkit.utils.log_tools'] = MagicMock()
    sys.modules['tanka_ai_toolkit.utils.log_tools.tanka_log'] = MagicMock()

    from core.queue.redis_group_queue.redis_group_queue_item import SimpleQueueItem
    from core.queue.redis_group_queue.redis_msg_group_queue_manager import ShutdownMode

    IMPORTS_AVAILABLE = True
    print("âœ… æˆåŠŸå¯¼å…¥æ ¸å¿ƒæ¨¡å—ï¼ˆä½¿ç”¨Mockä¾èµ–ï¼‰")
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥å¤±è´¥: {e}")
    print("å°†ä½¿ç”¨Mockå¯¹è±¡è¿›è¡Œæµ‹è¯•...")
    IMPORTS_AVAILABLE = False

    # åˆ›å»ºMockç±»
    class MockShutdownMode:
        SOFT = "soft"
        HARD = "hard"

    class MockSimpleQueueItem:
        def __init__(self, data, item_type):
            self.data = data
            self.item_type = item_type

    ShutdownMode = MockShutdownMode
    SimpleQueueItem = MockSimpleQueueItem


# ==================== åŸºæœ¬åŠŸèƒ½æµ‹è¯• ====================


async def test_basic_message_delivery_and_retrieval(manager_factory):
    """æµ‹è¯•åŸºæœ¬çš„æ¶ˆæ¯æŠ•é€’å’Œè·å–"""
    manager = await manager_factory.get_manager()

    # åˆ›å»ºç¤ºä¾‹æ¶ˆæ¯
    sample_message = SimpleQueueItem(
        data={"user_id": "12345", "content": "Hello World", "timestamp": time.time()},
        item_type="chat_message",
    )

    # æŠ•é€’æ¶ˆæ¯
    success = await manager.deliver_message("test_group_1", sample_message)
    assert success, "æ¶ˆæ¯æŠ•é€’åº”è¯¥æˆåŠŸ"

    # è·å–æ¶ˆæ¯
    messages = await manager.get_messages(score_threshold=0)
    assert len(messages) == 1, "åº”è¯¥è·å–åˆ°1æ¡æ¶ˆæ¯"

    retrieved_message = messages[0]
    assert retrieved_message.data["user_id"] == "12345"
    assert retrieved_message.data["content"] == "Hello World"
    assert retrieved_message.item_type == "chat_message"


async def test_message_delivery_limit(manager_factory):
    """æµ‹è¯•æ¶ˆæ¯æŠ•é€’ä¸Šé™"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="limit_test_manager", max_total_messages=3, auto_start=False
    )

    # æŠ•é€’æ¶ˆæ¯ç›´åˆ°è¾¾åˆ°ä¸Šé™
    for i in range(3):
        message = SimpleQueueItem(
            data={"id": i, "content": f"Message {i}"}, item_type="test"
        )
        success = await manager.deliver_message(f"group_{i}", message)
        assert success, f"ç¬¬{i+1}æ¡æ¶ˆæ¯åº”è¯¥æŠ•é€’æˆåŠŸ"

    # ç¬¬4æ¡æ¶ˆæ¯åº”è¯¥è¢«æ‹’ç»
    extra_message = SimpleQueueItem(
        data={"id": 4, "content": "Extra message"}, item_type="test"
    )
    success = await manager.deliver_message("group_4", extra_message)
    assert not success, "è¶…è¿‡ä¸Šé™çš„æ¶ˆæ¯åº”è¯¥è¢«æ‹’ç»"

    # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
    stats = await manager.get_manager_stats()
    assert stats["total_delivered_messages"] == 3
    assert stats["total_rejected_messages"] == 1


async def test_queue_statistics(manager_factory):
    """æµ‹è¯•é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="stats_test_manager", auto_start=False
    )

    # æŠ•é€’å‡ æ¡æ¶ˆæ¯åˆ°ä¸åŒåˆ†ç»„
    groups = ["stats_group_1", "stats_group_2", "stats_group_3"]
    for i, group in enumerate(groups):
        message = SimpleQueueItem(
            data={"id": i, "content": f"Stats message {i}"}, item_type="stats_test"
        )
        await manager.deliver_message(group, message)

    # è·å–ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯
    manager_stats = await manager.get_manager_stats()
    assert manager_stats["total_delivered_messages"] == 3
    assert manager_stats["total_current_messages"] == 3
    assert manager_stats["total_queues"] == 50  # å›ºå®šåˆ†åŒºæ•°é‡

    # è·å–ç‰¹å®šé˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
    queue_stats = await manager.get_queue_stats("stats_group_1")
    assert queue_stats is not None
    assert queue_stats["current_size"] >= 0  # å¯èƒ½è¢«è·¯ç”±åˆ°ä¸åŒåˆ†åŒº


async def test_improved_stats_functionality(manager_factory):
    """æµ‹è¯•æ”¹è¿›åçš„ç»Ÿè®¡åŠŸèƒ½"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="improved_stats_test", auto_start=False
    )

    # æŠ•é€’ä¸€äº›æµ‹è¯•æ¶ˆæ¯åˆ°ä¸åŒåˆ†ç»„
    test_groups = ["group_a", "group_b", "group_c"]
    for group in test_groups:
        for j in range(2):  # æ¯ä¸ªç»„æŠ•é€’2æ¡æ¶ˆæ¯
            message = SimpleQueueItem(
                data={"id": f"{group}_{j}", "content": f"Message {j} for {group}"},
                item_type="improved_stats_test",
            )
            await manager.deliver_message(group, message)

    print("\n=== æµ‹è¯•åŸºç¡€ç»Ÿè®¡åŠŸèƒ½ ===")

    # æµ‹è¯•1: åŸºç¡€ç®¡ç†å™¨ç»Ÿè®¡
    basic_stats = await manager.get_stats()
    print(
        f"åŸºç¡€ç»Ÿè®¡: type={basic_stats['type']}, æ¶ˆæ¯æ•°={basic_stats['actual_messages_in_queues']}"
    )
    assert basic_stats["type"] == "manager_stats"
    assert basic_stats["actual_messages_in_queues"] == 6  # 3ç»„ * 2æ¡æ¶ˆæ¯
    assert basic_stats["total_queues"] == 50

    # æµ‹è¯•2: å•ä¸ªé˜Ÿåˆ—ç»Ÿè®¡
    queue_stats = await manager.get_stats(group_key="group_a")
    print(f"é˜Ÿåˆ—ç»Ÿè®¡: type={queue_stats['type']}, é˜Ÿåˆ—å={queue_stats['queue_name']}")
    assert queue_stats["type"] == "queue_stats"
    assert "group_a" in queue_stats["queue_name"]
    assert "partition" in queue_stats

    # æµ‹è¯•3: åŒ…å«åˆ†åŒºè¯¦ç»†ä¿¡æ¯çš„ç»Ÿè®¡
    detailed_stats = await manager.get_stats(include_partition_details=True)
    print(f"è¯¦ç»†ç»Ÿè®¡: éç©ºåˆ†åŒºæ•°={detailed_stats['non_empty_partitions']}")
    assert "partitions" in detailed_stats
    assert detailed_stats["non_empty_partitions"] >= 1
    assert len(detailed_stats["partitions"]) == 50

    # æµ‹è¯•4: åŒ…å«æ¶ˆè´¹è€…ä¿¡æ¯çš„ç»Ÿè®¡
    consumer_stats = await manager.get_stats(include_consumer_info=True)
    print(f"æ¶ˆè´¹è€…ç»Ÿè®¡: æ´»è·ƒæ¶ˆè´¹è€…æ•°={consumer_stats['active_consumers_count']}")
    assert "active_consumers_count" in consumer_stats
    assert "active_consumers" in consumer_stats
    assert "partition_assignments" in consumer_stats

    # æµ‹è¯•5: å…¨åˆ†åŒºç»Ÿè®¡ï¼ˆæŒ‡å®šgroup_keyä½†åŒ…å«æ‰€æœ‰åˆ†åŒºï¼‰
    all_partitions_stats = await manager.get_stats(
        group_key="group_a", include_all_partitions=True, include_partition_details=True
    )
    print(f"å…¨åˆ†åŒºç»Ÿè®¡: type={all_partitions_stats['type']}")
    assert all_partitions_stats["type"] == "all_partitions_stats"
    assert "partitions" in all_partitions_stats

    print("âœ… æ”¹è¿›åçš„ç»Ÿè®¡åŠŸèƒ½æµ‹è¯•é€šè¿‡")


async def test_stats_performance_and_accuracy(manager_factory):
    """æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½çš„æ€§èƒ½å’Œå‡†ç¡®æ€§"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="stats_perf_test", auto_start=False
    )

    print("\n=== æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½æ€§èƒ½å’Œå‡†ç¡®æ€§ ===")

    # æŠ•é€’å¤§é‡æ¶ˆæ¯åˆ°ä¸åŒåˆ†åŒº
    message_count = 50
    for i in range(message_count):
        message = SimpleQueueItem(
            data={"id": i, "batch": "performance_test"}, item_type="perf_test"
        )
        await manager.deliver_message(f"perf_group_{i}", message)

    # æµ‹è¯•ç»Ÿè®¡å‡†ç¡®æ€§
    start_time = time.time()

    stats = await manager.get_stats(
        include_partition_details=True, include_consumer_info=True
    )

    end_time = time.time()
    duration = end_time - start_time

    print(f"ç»Ÿè®¡æŸ¥è¯¢è€—æ—¶: {duration:.3f}ç§’")
    print(f"å®é™…æ¶ˆæ¯æ•°: {stats['actual_messages_in_queues']}")
    print(f"è®¡æ•°å™¨æ€»æ•°: {stats['counter_total_count']}")
    print(f"éç©ºåˆ†åŒºæ•°: {stats['non_empty_partitions']}")

    # éªŒè¯å‡†ç¡®æ€§
    assert stats["actual_messages_in_queues"] == message_count
    assert stats["counter_total_count"] == message_count
    assert stats["non_empty_partitions"] >= 1
    assert duration < 6.0  # ç»Ÿè®¡æŸ¥è¯¢åº”è¯¥åœ¨6ç§’å†…å®Œæˆ(5s rate limit)

    # éªŒè¯åˆ†åŒºç»Ÿè®¡çš„æ€»å’Œç­‰äºå®é™…æ¶ˆæ¯æ•°
    total_in_partitions = sum(p["current_size"] for p in stats["partitions"])
    assert total_in_partitions == message_count

    print("âœ… ç»Ÿè®¡åŠŸèƒ½æ€§èƒ½å’Œå‡†ç¡®æ€§æµ‹è¯•é€šè¿‡")


async def test_stats_error_handling(manager_factory):
    """æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½çš„é”™è¯¯å¤„ç†"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="stats_error_test", auto_start=False
    )

    print("\n=== æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½é”™è¯¯å¤„ç† ===")

    # æµ‹è¯•æ­£å¸¸æƒ…å†µ
    normal_stats = await manager.get_stats()
    assert normal_stats["type"] != "error_fallback"

    # æµ‹è¯•ç©ºé˜Ÿåˆ—ç»Ÿè®¡
    empty_stats = await manager.get_stats(group_key="nonexistent_group")
    assert empty_stats["type"] == "queue_stats"
    assert empty_stats["current_size"] == 0

    print("âœ… ç»Ÿè®¡åŠŸèƒ½é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")


# ==================== åˆ†ç»„è·¯ç”±æµ‹è¯• ====================


async def test_group_key_routing_consistency(manager_factory):
    """æµ‹è¯•åˆ†ç»„é”®è·¯ç”±çš„ä¸€è‡´æ€§"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="routing_test_manager", auto_start=False  # ç¦ç”¨è‡ªåŠ¨å¯åŠ¨å®šæœŸä»»åŠ¡
    )

    # åŒä¸€ä¸ªgroup_keyåº”è¯¥æ€»æ˜¯è·¯ç”±åˆ°åŒä¸€ä¸ªåˆ†åŒº
    group_key = "consistent_group"

    partitions = set()
    for _ in range(10):
        partition = manager._hash_group_key_to_partition(
            group_key
        )  # pylint: disable=protected-access
        partitions.add(partition)

    assert len(partitions) == 1, "åŒä¸€ä¸ªgroup_keyåº”è¯¥æ€»æ˜¯è·¯ç”±åˆ°åŒä¸€ä¸ªåˆ†åŒº"

    # éªŒè¯æ¶ˆæ¯ç¡®å®è¢«æŠ•é€’åˆ°æ­£ç¡®çš„åˆ†åŒºé˜Ÿåˆ—
    target_partition = manager._hash_group_key_to_partition(
        group_key
    )  # pylint: disable=protected-access
    target_queue_key = manager._get_queue_key(
        target_partition
    )  # pylint: disable=protected-access

    # æŠ•é€’æµ‹è¯•æ¶ˆæ¯
    test_message = SimpleQueueItem(
        data={"test": "routing_consistency", "group": group_key},
        item_type="routing_test",
    )
    success = await manager.deliver_message(group_key, test_message)
    assert success, "æ¶ˆæ¯æŠ•é€’åº”è¯¥æˆåŠŸ"

    # éªŒè¯æ¶ˆæ¯åœ¨æ­£ç¡®çš„åˆ†åŒºé˜Ÿåˆ—ä¸­
    queue_size = await manager.redis_client.zcard(target_queue_key)
    assert queue_size == 1, f"ç›®æ ‡åˆ†åŒº{target_partition}åº”è¯¥åŒ…å«1æ¡æ¶ˆæ¯"

    # éªŒè¯å…¶ä»–åˆ†åŒºæ²¡æœ‰è¿™æ¡æ¶ˆæ¯ï¼ˆæ£€æŸ¥å‰5ä¸ªä¸åŒçš„åˆ†åŒºï¼‰
    other_partitions = [
        p for p in manager.partition_names[:10] if p != target_partition
    ][:5]
    for other_partition in other_partitions:
        other_queue_key = manager._get_queue_key(
            other_partition
        )  # pylint: disable=protected-access
        other_size = await manager.redis_client.zcard(other_queue_key)
        # æ³¨æ„ï¼šå…¶ä»–åˆ†åŒºå¯èƒ½æœ‰æ¥è‡ªå…¶ä»–æµ‹è¯•çš„æ¶ˆæ¯ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸èƒ½æ–­è¨€ä¸º0
        # ä½†æˆ‘ä»¬å¯ä»¥è®°å½•è¿™ä¸ªä¿¡æ¯ç”¨äºè°ƒè¯•
        print(f"åˆ†åŒº{other_partition}æ¶ˆæ¯æ•°: {other_size}")

    print(f"âœ… æ¶ˆæ¯æˆåŠŸè·¯ç”±åˆ°åˆ†åŒº{target_partition}ï¼Œé˜Ÿåˆ—å¤§å°: {queue_size}")


async def test_group_key_distribution(manager_factory):
    """æµ‹è¯•åˆ†ç»„é”®åˆ†å¸ƒçš„å‡åŒ€æ€§"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="distribution_test_manager", auto_start=False
    )

    # ç”Ÿæˆå¤§é‡ä¸åŒçš„group_keyï¼Œæ£€æŸ¥åˆ†å¸ƒæ˜¯å¦ç›¸å¯¹å‡åŒ€
    partitions = {}

    for i in range(1000):
        group_key = f"group_{i}"
        partition = manager._hash_group_key_to_partition(
            group_key
        )  # pylint: disable=protected-access
        partitions[partition] = partitions.get(partition, 0) + 1

    # æ£€æŸ¥åˆ†å¸ƒæ˜¯å¦ç›¸å¯¹å‡åŒ€ï¼ˆå…è®¸ä¸€å®šçš„åå·®ï¼‰
    # å¹³å‡æ¯ä¸ªåˆ†åŒº10ä¸ªï¼Œå…è®¸1-50çš„èŒƒå›´
    for partition, count in partitions.items():
        assert 1 <= count <= 50, f"åˆ†åŒº{partition}çš„åˆ†å¸ƒä¸å‡åŒ€: {count}"


# ==================== Scoreé˜ˆå€¼æµ‹è¯• ====================


async def test_score_threshold_filtering(manager_factory):
    """æµ‹è¯•scoreé˜ˆå€¼è¿‡æ»¤åŠŸèƒ½"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="threshold_test_manager", auto_start=False
    )

    # æŠ•é€’ä¸¤æ¡æ¶ˆæ¯ï¼Œæ—¶é—´é—´éš”å¾ˆå°
    message1 = SimpleQueueItem(
        data={"id": 1, "content": "First message"}, item_type="threshold_test"
    )
    message2 = SimpleQueueItem(
        data={"id": 2, "content": "Second message"}, item_type="threshold_test"
    )

    await manager.deliver_message("threshold_group", message1)
    await asyncio.sleep(0.001)  # å¾ˆå°çš„æ—¶é—´é—´éš”
    await manager.deliver_message("threshold_group", message2)

    # ä½¿ç”¨å¾ˆå¤§çš„é˜ˆå€¼ï¼Œåº”è¯¥è·å–ä¸åˆ°æ¶ˆæ¯
    messages = await manager.get_messages(score_threshold=10000)  # 10ç§’çš„æ¯«ç§’æ•°
    assert len(messages) == 0, "ä½¿ç”¨å¤§é˜ˆå€¼åº”è¯¥è·å–ä¸åˆ°æ¶ˆæ¯"

    # ä½¿ç”¨å¾ˆå°çš„é˜ˆå€¼ï¼Œåº”è¯¥èƒ½è·å–åˆ°æ¶ˆæ¯
    messages = await manager.get_messages(score_threshold=1)  # 1æ¯«ç§’
    assert len(messages) >= 1, "ä½¿ç”¨å°é˜ˆå€¼åº”è¯¥èƒ½è·å–åˆ°æ¶ˆæ¯"


async def test_single_message_queue_boundary_case(manager_factory):
    """æµ‹è¯•é˜Ÿåˆ—åªæœ‰ä¸€ä¸ªæ¶ˆæ¯æ—¶çš„è¾¹ç•Œæƒ…å†µå¤„ç†"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="single_msg_test_manager", auto_start=False
    )

    # æŠ•é€’ä¸€æ¡æ¶ˆæ¯
    message = SimpleQueueItem(
        data={"id": 1, "content": "Single message"}, item_type="boundary_test"
    )

    await manager.deliver_message("single_msg_group", message)

    # è·å–å½“å‰æ—¶é—´ä½œä¸ºcurrent_score
    current_time = int(time.time() * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’æ•´æ•°

    # ä½¿ç”¨current_scoreå’Œè¾ƒå°çš„é˜ˆå€¼ï¼Œåº”è¯¥èƒ½è·å–åˆ°æ¶ˆæ¯
    messages = await manager.get_messages(
        score_threshold=50,  # 50æ¯«ç§’é˜ˆå€¼
        current_score=current_time + 100,  # æ¨¡æ‹Ÿ100æ¯«ç§’åçš„æ—¶é—´
    )
    assert len(messages) == 1, "å•æ¶ˆæ¯é˜Ÿåˆ—åº”è¯¥èƒ½æ ¹æ®current_scoreè·å–åˆ°æ¶ˆæ¯"
    assert messages[0].data["id"] == 1, "è·å–åˆ°çš„åº”è¯¥æ˜¯æŠ•é€’çš„æ¶ˆæ¯"

    # å†æ¬¡æŠ•é€’ä¸€æ¡æ¶ˆæ¯ï¼Œæµ‹è¯•é˜Ÿåˆ—ä¸ºç©ºåé‡æ–°æŠ•é€’çš„æƒ…å†µ
    message2 = SimpleQueueItem(
        data={"id": 2, "content": "Second single message"}, item_type="boundary_test"
    )

    await manager.deliver_message("single_msg_group", message2)

    # ä½¿ç”¨å¾ˆå¤§çš„é˜ˆå€¼ï¼Œåº”è¯¥è·å–ä¸åˆ°æ¶ˆæ¯
    messages = await manager.get_messages(
        score_threshold=10000,  # 10ç§’é˜ˆå€¼
        current_score=current_time + 50,  # åªæœ‰50æ¯«ç§’å·®å€¼
    )
    assert len(messages) == 0, "é˜ˆå€¼å¤ªå¤§æ—¶å•æ¶ˆæ¯é˜Ÿåˆ—åº”è¯¥è·å–ä¸åˆ°æ¶ˆæ¯"

    # ä½¿ç”¨åˆé€‚çš„é˜ˆå€¼ï¼Œåº”è¯¥èƒ½è·å–åˆ°æ¶ˆæ¯
    messages = await manager.get_messages(
        score_threshold=1500,  # 1500æ¯«ç§’é˜ˆå€¼
        current_score=current_time + 5000,  # 5000æ¯«ç§’å·®å€¼
    )
    assert len(messages) == 1, "é˜ˆå€¼åˆé€‚æ—¶å•æ¶ˆæ¯é˜Ÿåˆ—åº”è¯¥èƒ½è·å–åˆ°æ¶ˆæ¯"
    assert messages[0].data["id"] == 2, "è·å–åˆ°çš„åº”è¯¥æ˜¯ç¬¬äºŒæ¡æ¶ˆæ¯"


async def test_score_logic_with_old_timestamps(manager_factory):
    """æµ‹è¯•scoreé€»è¾‘ï¼šéªŒè¯æ—§æ—¶é—´æˆ³æ¶ˆæ¯çš„è·å–è¡Œä¸º"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="score_logic_test_manager", auto_start=False
    )

    # è·å–å½“å‰æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
    current_time = int(time.time() * 1000)

    # 10å¤©6åˆ†é’Ÿå‰çš„æ—¶é—´æˆ³
    ten_days_6mins_ago = current_time - (10 * 24 * 60 * 60 * 1000 + 6 * 60 * 1000)

    print(f"å½“å‰æ—¶é—´: {current_time}")
    print(f"10å¤©6åˆ†é’Ÿå‰: {ten_days_6mins_ago}")

    # === æµ‹è¯•1: æŠ•é€’1000ä¸ª10å¤©å‰çš„æ¶ˆæ¯ï¼Œ1000ä¸ªæ¶ˆæ¯çš„æ—¶é—´è·¨åº¦åœ¨5åˆ†é’Ÿå†… ===
    print("\n=== æµ‹è¯•1: æŠ•é€’1000ä¸ª10å¤©å‰çš„æ¶ˆæ¯ï¼Œæ—¶é—´è·¨åº¦5åˆ†é’Ÿ ===")

    # åˆ›å»ºè‡ªå®šä¹‰æ’åºå‡½æ•°ï¼Œä½¿ç”¨æŒ‡å®šçš„æ—¶é—´æˆ³
    def old_timestamp_sort_key(item):
        # ä»æ¶ˆæ¯æ•°æ®ä¸­è·å–é¢„è®¾çš„æ—¶é—´æˆ³
        return item.data.get("timestamp", current_time)

    manager.sort_key_func = old_timestamp_sort_key

    # æŠ•é€’1000ä¸ªæ¶ˆæ¯ï¼Œ1000ä¸ªæ¶ˆæ¯çš„æ—¶é—´è·¨åº¦åœ¨5åˆ†é’Ÿå†…ï¼ˆæ¯ä¸ªæ¶ˆæ¯é—´éš”çº¦0.3ç§’ï¼‰
    current_time = int(time.time() * 1000)
    time_span_ms = 5 * 60 * 1000  # 5åˆ†é’Ÿçš„æ¯«ç§’æ•°
    for i in range(1000):
        # å°†1000ä¸ªæ¶ˆæ¯å‡åŒ€åˆ†å¸ƒåœ¨5åˆ†é’Ÿå†…
        message_timestamp = current_time + int(
            (i / 999) * time_span_ms
        )  # ä»0åˆ°time_span_mså‡åŒ€åˆ†å¸ƒ
        message = SimpleQueueItem(
            data={
                "id": i,
                "timestamp": message_timestamp,
                "content": f"Old message {i}",
            },
            item_type="old_timestamp_test",
        )
        await manager.deliver_message(f"old_group_{i % 10}", message)  # åˆ†æ•£åˆ°10ä¸ªç»„

    # å°è¯•è·å–100æ¬¡ï¼Œåº”è¯¥éƒ½è·å–ä¸åˆ°ï¼ˆå› ä¸º1000ä¸ªæ¶ˆæ¯çš„æœ€å¤§æœ€å°æ—¶é—´å·®åªæœ‰5åˆ†é’Ÿï¼Œå°äº6åˆ†é’Ÿé˜ˆå€¼ï¼‰
    retrieved_count = 0
    for attempt in range(20):
        messages = await manager.get_messages(
            score_threshold=7 * 60 * 1000, current_score=current_time + 6 * 60 * 1000
        )
        retrieved_count += len(messages)
        if len(messages) > 0:
            print(f"ç¬¬{attempt+1}æ¬¡è·å–åˆ°{len(messages)}ä¸ªæ¶ˆæ¯")

    print(
        f"æ€»å…±è·å–åˆ° {retrieved_count} ä¸ªæ¶ˆæ¯ï¼ˆé¢„æœŸï¼š0ä¸ªï¼Œå› ä¸ºæœ€å¤§æœ€å°æ—¶é—´å·®åªæœ‰5åˆ†é’Ÿï¼‰"
    )
    assert retrieved_count == 0, f"åº”è¯¥è·å–ä¸åˆ°ä»»ä½•æ¶ˆæ¯ï¼Œä½†è·å–åˆ°äº†{retrieved_count}ä¸ª"

    # === æ¸…ç©ºæ•°æ®åº“ ===
    print("\n=== æ¸…ç©ºæ•°æ®åº“ ===")
    await manager.force_cleanup_and_reset()

    # === æµ‹è¯•2: æ··åˆæ—¶é—´æˆ³æ¶ˆæ¯æµ‹è¯• ===
    print("\n=== æµ‹è¯•2: æ··åˆæ—¶é—´æˆ³æ¶ˆæ¯æµ‹è¯• ===")

    # æŠ•é€’1ä¸ªå½“å‰çš„æ¶ˆæ¯
    now = int(time.time() * 1000)
    old_message = SimpleQueueItem(
        data={"id": "old", "timestamp": now, "content": "å½“å‰çš„æ¶ˆæ¯"},
        item_type="mixed_test",
    )
    await manager.deliver_message("mixed_group", old_message)

    # æŠ•é€’5ä¸ª10å¤©6åˆ†é’Ÿå‰çš„æ¶ˆæ¯
    for i in range(5):
        very_old_message = SimpleQueueItem(
            data={
                "id": f"very_old_{i}",
                "timestamp": ten_days_6mins_ago + (i * 1000),
                "content": f"10å¤©6åˆ†é’Ÿå‰çš„æ¶ˆæ¯{i}",
            },
            item_type="mixed_test",
        )
        await manager.deliver_message("mixed_group", very_old_message)

    for i in range(5):
        messages = await manager.get_messages(
            score_threshold=5 * 60 * 1000, current_score=now
        )
        assert len(messages) == 1, f"åº”è¯¥è·å–åˆ°1æ¡æ¶ˆæ¯ï¼Œå®é™…è·å–åˆ°{len(messages)}æ¡"
        assert (
            messages[0].data['id'] == f"very_old_{i}"
        ), f"åº”è¯¥è·å–åˆ°10å¤©6åˆ†é’Ÿå‰çš„æ¶ˆæ¯ï¼Œå®é™…è·å–åˆ°{messages[0].data['id']}"

    messages = await manager.get_messages(
        score_threshold=5 * 60 * 1000, current_score=now
    )
    assert len(messages) == 0, f"åº”è¯¥è·å–åˆ°0æ¡æ¶ˆæ¯ï¼Œå®é™…è·å–åˆ°{len(messages)}æ¡"


async def test_out_of_order_insertion_ordered_retrieval(manager_factory):
    """æµ‹è¯•ä¹±åºæ’å…¥ã€é¡ºåºå–å‡ºåŠŸèƒ½"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="order_test_manager", auto_start=False
    )

    # åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„æ’åºå‡½æ•°ï¼ŒåŸºäºæ¶ˆæ¯IDæ’åº
    def custom_sort_key(item: SimpleQueueItem) -> int:
        return int(item.data.get("order_id", 0))

    # é‡æ–°è®¾ç½®æ’åºå‡½æ•°
    manager.sort_key_func = custom_sort_key

    # ä¹±åºæŠ•é€’æ¶ˆæ¯ï¼ˆæŒ‰order_id: 3, 1, 4, 2çš„é¡ºåºæŠ•é€’ï¼‰
    messages_to_deliver = [
        SimpleQueueItem(
            data={"order_id": 3, "content": "Third message"}, item_type="order_test"
        ),
        SimpleQueueItem(
            data={"order_id": 1, "content": "First message"}, item_type="order_test"
        ),
        SimpleQueueItem(
            data={"order_id": 4, "content": "Fourth message"}, item_type="order_test"
        ),
        SimpleQueueItem(
            data={"order_id": 2, "content": "Second message"}, item_type="order_test"
        ),
    ]

    # æŠ•é€’åˆ°åŒä¸€ä¸ªåˆ†ç»„ï¼Œç¡®ä¿åœ¨åŒä¸€ä¸ªåˆ†åŒº
    group_key = "order_test_group"
    for msg in messages_to_deliver:
        success = await manager.deliver_message(group_key, msg)
        assert success, f"æ¶ˆæ¯{msg.data['order_id']}æŠ•é€’åº”è¯¥æˆåŠŸ"
        await asyncio.sleep(0.001)  # å°å»¶è¿Ÿç¡®ä¿æ—¶é—´æˆ³ä¸åŒ

    # è¿ç»­è·å–æ¶ˆæ¯4æ¬¡ï¼Œæ¯æ¬¡åº”è¯¥æŒ‰order_idé¡ºåºè¿”å›ï¼ˆ1, 2, 3, 4ï¼‰
    retrieved_messages = []
    expected_order = [1, 2, 3, 4]
    expected_contents = [
        "First message",
        "Second message",
        "Third message",
        "Fourth message",
    ]

    for i in range(4):
        messages = await manager.get_messages(score_threshold=0)
        assert (
            len(messages) == 1
        ), f"ç¬¬{i+1}æ¬¡è·å–åº”è¯¥å¾—åˆ°1æ¡æ¶ˆæ¯ï¼Œå®é™…è·å–åˆ°{len(messages)}æ¡"
        retrieved_messages.extend(messages)

    # éªŒè¯æ€»æ¶ˆæ¯æ•°é‡
    assert (
        len(retrieved_messages) == 4
    ), f"æ€»å…±åº”è¯¥è·å–åˆ°4æ¡æ¶ˆæ¯ï¼Œå®é™…è·å–åˆ°{len(retrieved_messages)}æ¡"

    # éªŒè¯æ¶ˆæ¯é¡ºåº
    actual_order = [msg.data["order_id"] for msg in retrieved_messages]

    print(f"æœŸæœ›é¡ºåº: {expected_order}")
    print(f"å®é™…é¡ºåº: {actual_order}")

    assert (
        actual_order == expected_order
    ), f"æ¶ˆæ¯é¡ºåºä¸æ­£ç¡®ï¼ŒæœŸæœ›{expected_order}ï¼Œå®é™…{actual_order}"

    # éªŒè¯æ¶ˆæ¯å†…å®¹
    actual_contents = [msg.data["content"] for msg in retrieved_messages]
    assert (
        actual_contents == expected_contents
    ), f"æ¶ˆæ¯å†…å®¹é¡ºåºä¸æ­£ç¡®ï¼ŒæœŸæœ›{expected_contents}ï¼Œå®é™…{actual_contents}"


# ==================== æ¶ˆè´¹è€…ç®¡ç†æµ‹è¯• ====================


async def test_consumer_join_and_exit(manager_factory):
    """æµ‹è¯•æ¶ˆè´¹è€…åŠ å…¥å’Œé€€å‡º"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="consumer_test_manager", auto_start=False
    )

    # æµ‹è¯•åŠ å…¥æ¶ˆè´¹è€…
    owner_count, partitions = await manager.join_consumer("test_consumer_1")
    assert owner_count == 1, "åº”è¯¥æœ‰1ä¸ªæ¶ˆè´¹è€…"
    assert "test_consumer_1" in partitions, "æ¶ˆè´¹è€…åº”è¯¥è¢«åˆ†é…åˆ†åŒº"
    assert len(partitions["test_consumer_1"]) == 50, "å•ä¸ªæ¶ˆè´¹è€…åº”è¯¥è·å¾—æ‰€æœ‰åˆ†åŒº"

    # åŠ å…¥ç¬¬äºŒä¸ªæ¶ˆè´¹è€…
    owner_count, partitions = await manager.join_consumer("test_consumer_2")
    assert owner_count == 2, "åº”è¯¥æœ‰2ä¸ªæ¶ˆè´¹è€…"
    assert len(partitions["test_consumer_1"]) + len(partitions["test_consumer_2"]) == 50

    # é€€å‡ºä¸€ä¸ªæ¶ˆè´¹è€…
    owner_count, exit_partitions = await manager.exit_consumer("test_consumer_1")
    assert owner_count == 1, "åº”è¯¥å‰©ä½™1ä¸ªæ¶ˆè´¹è€…"
    assert "test_consumer_1" not in exit_partitions, "é€€å‡ºçš„æ¶ˆè´¹è€…ä¸åº”è¯¥æœ‰åˆ†åŒº"
    assert len(exit_partitions["test_consumer_2"]) == 50, "å‰©ä½™æ¶ˆè´¹è€…åº”è¯¥è·å¾—æ‰€æœ‰åˆ†åŒº"


async def test_consumer_keepalive(manager_factory):
    """æµ‹è¯•æ¶ˆè´¹è€…ä¿æ´»"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="keepalive_test_manager", auto_start=False
    )

    # åŠ å…¥æ¶ˆè´¹è€…
    await manager.join_consumer("keepalive_consumer")

    # æµ‹è¯•ä¿æ´»
    success = await manager.keepalive_consumer("keepalive_consumer")
    assert success, "ä¿æ´»åº”è¯¥æˆåŠŸ"

    # æµ‹è¯•ä¸å­˜åœ¨çš„æ¶ˆè´¹è€…ä¿æ´»
    success = await manager.keepalive_consumer("nonexistent_consumer")
    assert not success, "ä¸å­˜åœ¨çš„æ¶ˆè´¹è€…ä¿æ´»åº”è¯¥å¤±è´¥"


async def test_automatic_consumer_join_on_get_messages(manager_factory):
    """æµ‹è¯•è·å–æ¶ˆæ¯æ—¶è‡ªåŠ¨åŠ å…¥æ¶ˆè´¹è€…"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="auto_join_test_manager", auto_start=False
    )

    # æŠ•é€’æ¶ˆæ¯
    sample_message = SimpleQueueItem(
        data={"user_id": "12345", "content": "Hello World", "timestamp": time.time()},
        item_type="chat_message",
    )
    await manager.deliver_message("auto_join_group", sample_message)

    # ç›´æ¥è·å–æ¶ˆæ¯ï¼ˆåº”è¯¥è‡ªåŠ¨åŠ å…¥æ¶ˆè´¹è€…ï¼‰
    messages = await manager.get_messages(score_threshold=0)
    assert len(messages) == 1, "åº”è¯¥è‡ªåŠ¨åŠ å…¥æ¶ˆè´¹è€…å¹¶è·å–åˆ°æ¶ˆæ¯"


# ==================== Rebalanceæµ‹è¯• ====================


async def test_rebalance_partitions(manager_factory):
    """æµ‹è¯•åˆ†åŒºé‡æ–°å¹³è¡¡"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="rebalance_test_manager", auto_start=False
    )

    # åŠ å…¥å¤šä¸ªæ¶ˆè´¹è€…
    consumers = ["rebalance_1", "rebalance_2", "rebalance_3"]
    for consumer in consumers:
        await manager.join_consumer(consumer)

    # æ‰‹åŠ¨è§¦å‘rebalance
    owner_count, rebalance_result = await manager.rebalance_partitions()
    assert owner_count == 3, "åº”è¯¥æœ‰3ä¸ªæ¶ˆè´¹è€…"

    # éªŒè¯åˆ†åŒºåˆ†é… - å¤„ç†è¿”å›ç»“æœå¯èƒ½æ˜¯åˆ—è¡¨çš„æƒ…å†µ
    if isinstance(rebalance_result, dict):
        total_partitions = sum(len(parts) for parts in rebalance_result.values())
        partition_counts = [len(parts) for parts in rebalance_result.values()]
    else:
        # å¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œè¯´æ˜æ²¡æœ‰åˆ†åŒºåˆ†é…ï¼ˆç©ºç»“æœï¼‰
        print(f"âš ï¸ rebalance_result æ˜¯åˆ—è¡¨ç±»å‹: {rebalance_result}")
        total_partitions = 0
        partition_counts = []

    assert total_partitions == 50, f"æ‰€æœ‰åˆ†åŒºéƒ½åº”è¯¥è¢«åˆ†é…ï¼Œå®é™…åˆ†é…: {total_partitions}"

    # éªŒè¯åˆ†é…çš„ç›¸å¯¹å‡åŒ€æ€§
    if partition_counts:
        assert (
            max(partition_counts) - min(partition_counts) <= 1
        ), "åˆ†åŒºåˆ†é…åº”è¯¥ç›¸å¯¹å‡åŒ€"


async def test_rebalance_with_uneven_partitions(manager_factory):
    """æµ‹è¯•ä¸èƒ½æ•´é™¤æ—¶çš„åˆ†åŒºå¹³è¡¡"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="uneven_test_manager", auto_start=False
    )

    # å…ˆå¼ºåˆ¶æ¸…ç†ï¼Œç¡®ä¿æ²¡æœ‰å…¶ä»–æµ‹è¯•çš„æ®‹ç•™æ¶ˆè´¹è€…
    await manager.force_cleanup_and_reset()

    # åŠ å…¥7ä¸ªæ¶ˆè´¹è€…ï¼ˆ50ä¸èƒ½è¢«7æ•´é™¤ï¼‰
    consumers = [f"uneven_{i}" for i in range(7)]
    for consumer in consumers:
        await manager.join_consumer(consumer)

    owner_count, uneven_partitions = await manager.rebalance_partitions()

    print(f"ğŸ” å®é™…owneræ•°é‡: {owner_count}")
    print(f"ğŸ” åˆ†åŒºåˆ†é…ç»“æœ: {uneven_partitions}")

    assert owner_count == 7, f"åº”è¯¥æœ‰7ä¸ªæ¶ˆè´¹è€…ï¼Œå®é™…æœ‰{owner_count}ä¸ª"

    # éªŒè¯åˆ†åŒºåˆ†é… - å¤„ç†è¿”å›ç»“æœå¯èƒ½æ˜¯åˆ—è¡¨çš„æƒ…å†µ
    if isinstance(uneven_partitions, dict):
        partition_counts = [len(parts) for parts in uneven_partitions.values()]
        partition_counts.sort()

        print(f"ğŸ” åˆ†åŒºæ•°é‡åˆ†å¸ƒ: {partition_counts}")

        # 50 / 7 = 7 ä½™ 1ï¼Œæ‰€ä»¥åº”è¯¥æœ‰1ä¸ªæ¶ˆè´¹è€…åˆ†åˆ°8ä¸ªåˆ†åŒºï¼Œ6ä¸ªæ¶ˆè´¹è€…åˆ†åˆ°7ä¸ªåˆ†åŒº
        expected_counts = [7, 7, 7, 7, 7, 7, 8]
        assert (
            partition_counts == expected_counts
        ), f"åˆ†åŒºåˆ†é…ä¸æ­£ç¡®ï¼ŒæœŸæœ›{expected_counts}ï¼Œå®é™…{partition_counts}"
    else:
        # å¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œè¯´æ˜æ²¡æœ‰åˆ†åŒºåˆ†é…ï¼ˆç©ºç»“æœï¼‰
        print(f"âš ï¸ uneven_partitions æ˜¯åˆ—è¡¨ç±»å‹: {uneven_partitions}")
        assert False, "åˆ†åŒºåˆ†é…åº”è¯¥è¿”å›å­—å…¸æ ¼å¼"


# ==================== æ¸…ç†åŠŸèƒ½æµ‹è¯• ====================


async def test_cleanup_inactive_owners(manager_factory):
    """æµ‹è¯•æ¸…ç†ä¸æ´»è·ƒæ¶ˆè´¹è€…"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="cleanup_test_manager", auto_start=False
    )

    # å…ˆå¼ºåˆ¶æ¸…ç†ï¼Œç¡®ä¿æ²¡æœ‰å…¶ä»–æµ‹è¯•çš„æ®‹ç•™æ¶ˆè´¹è€…
    await manager.force_cleanup_and_reset()

    # åŠ å…¥æ¶ˆè´¹è€…
    await manager.join_consumer("active_consumer")
    await manager.join_consumer("inactive_consumer")

    # éªŒè¯åˆå§‹çŠ¶æ€
    initial_owners = await manager.redis_client.zrange(
        manager.owner_activate_time_zset_key, 0, -1
    )
    print(f"ğŸ” åˆå§‹æ¶ˆè´¹è€…: {initial_owners}")
    assert len(initial_owners) == 2, f"åº”è¯¥æœ‰2ä¸ªæ¶ˆè´¹è€…ï¼Œå®é™…æœ‰{len(initial_owners)}ä¸ª"

    # æ¨¡æ‹Ÿæ—¶é—´æµé€ï¼Œè®©ä¸€ä¸ªæ¶ˆè´¹è€…å˜ä¸ºä¸æ´»è·ƒ
    # è¿™é‡Œæˆ‘ä»¬éœ€è¦ç›´æ¥æ“ä½œRedisæ¥æ¨¡æ‹Ÿè¿‡æœŸçš„æ—¶é—´æˆ³
    old_timestamp = time.time() - 3600  # 1å°æ—¶å‰
    await manager.redis_client.zadd(
        manager.owner_activate_time_zset_key, {"inactive_consumer": old_timestamp}
    )

    # éªŒè¯æ—¶é—´æˆ³è®¾ç½®
    inactive_score = await manager.redis_client.zscore(
        manager.owner_activate_time_zset_key, "inactive_consumer"
    )
    active_score = await manager.redis_client.zscore(
        manager.owner_activate_time_zset_key, "active_consumer"
    )
    print(f"ğŸ” inactive_consumeræ—¶é—´æˆ³: {inactive_score}")
    print(f"ğŸ” active_consumeræ—¶é—´æˆ³: {active_score}")
    print(f"ğŸ” å½“å‰æ—¶é—´: {time.time()}")
    print(f"ğŸ” ä¸æ´»è·ƒé˜ˆå€¼: {time.time() - manager.inactive_threshold_seconds}")

    # æ‰§è¡Œæ¸…ç†
    cleaned_count, owner_count, cleanup_result = await manager.cleanup_inactive_owners()

    print(f"ğŸ” æ¸…ç†ç»“æœ: cleaned_count={cleaned_count}, owner_count={owner_count}")
    print(f"ğŸ” æ¸…ç†ååˆ†åŒºåˆ†é…: {cleanup_result}")

    # éªŒè¯æ¸…ç†åçš„çŠ¶æ€
    remaining_owners = await manager.redis_client.zrange(
        manager.owner_activate_time_zset_key, 0, -1
    )
    print(f"ğŸ” å‰©ä½™æ¶ˆè´¹è€…: {remaining_owners}")

    assert cleaned_count == 1, f"åº”è¯¥æ¸…ç†1ä¸ªä¸æ´»è·ƒæ¶ˆè´¹è€…ï¼Œå®é™…æ¸…ç†äº†{cleaned_count}ä¸ª"
    assert owner_count == 1, f"åº”è¯¥å‰©ä½™1ä¸ªæ´»è·ƒæ¶ˆè´¹è€…ï¼Œå®é™…å‰©ä½™{owner_count}ä¸ª"
    assert "inactive_consumer" not in cleanup_result, "ä¸æ´»è·ƒæ¶ˆè´¹è€…åº”è¯¥è¢«æ¸…ç†"
    assert "active_consumer" in cleanup_result, "æ´»è·ƒæ¶ˆè´¹è€…åº”è¯¥ä¿ç•™"


async def test_force_cleanup_and_reset(manager_factory):
    """æµ‹è¯•å¼ºåˆ¶æ¸…ç†å’Œé‡ç½®"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="force_cleanup_test_manager", auto_start=False
    )

    # åŠ å…¥å‡ ä¸ªæ¶ˆè´¹è€…
    consumers = ["force_1", "force_2", "force_3"]
    for consumer in consumers:
        await manager.join_consumer(consumer)

    # æ‰§è¡Œå¼ºåˆ¶æ¸…ç†
    cleaned_count = await manager.force_cleanup_and_reset()
    assert cleaned_count == 3, "åº”è¯¥æ¸…ç†3ä¸ªæ¶ˆè´¹è€…"

    # éªŒè¯æ¸…ç†ç»“æœ
    owners = await manager.redis_client.zrange(
        manager.owner_activate_time_zset_key, 0, -1
    )
    assert len(owners) == 0, "æ‰€æœ‰æ¶ˆè´¹è€…åº”è¯¥è¢«æ¸…ç†"


# ==================== è¾¹è§’æƒ…å†µæµ‹è¯• ====================


async def test_empty_queue_operations(manager_factory):
    """æµ‹è¯•ç©ºé˜Ÿåˆ—æ“ä½œ"""
    manager = await manager_factory.get_manager()

    # ä»ç©ºé˜Ÿåˆ—è·å–æ¶ˆæ¯
    messages = await manager.get_messages(score_threshold=0)
    assert len(messages) == 0, f"ç©ºé˜Ÿåˆ—åº”è¯¥è¿”å›ç©ºåˆ—è¡¨ï¼Œä½†è·å–åˆ°{len(messages)}æ¡æ¶ˆæ¯"

    # è·å–ç©ºé˜Ÿåˆ—ç»Ÿè®¡
    stats = await manager.get_manager_stats()
    assert (
        stats["total_current_messages"] == 0
    ), f"ç©ºé˜Ÿåˆ—å½“å‰æ¶ˆæ¯æ•°åº”è¯¥ä¸º0ï¼Œä½†å®é™…ä¸º{stats['total_current_messages']}"


async def test_nonexistent_consumer_operations(manager_factory):
    """æµ‹è¯•ä¸å­˜åœ¨çš„æ¶ˆè´¹è€…æ“ä½œ"""
    manager = await manager_factory.get_manager()

    # é€€å‡ºä¸å­˜åœ¨çš„æ¶ˆè´¹è€…
    owner_count, _ = await manager.exit_consumer("nonexistent")
    assert owner_count == 0, f"é€€å‡ºä¸å­˜åœ¨çš„æ¶ˆè´¹è€…åº”è¯¥è¿”å›0ï¼Œä½†è¿”å›äº†{owner_count}"

    # ä¿æ´»ä¸å­˜åœ¨çš„æ¶ˆè´¹è€…
    success = await manager.keepalive_consumer("nonexistent")
    assert not success, "ä¸å­˜åœ¨çš„æ¶ˆè´¹è€…ä¿æ´»åº”è¯¥å¤±è´¥"


async def test_duplicate_message_handling(manager_factory):
    """æµ‹è¯•é‡å¤æ¶ˆæ¯å¤„ç†"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="duplicate_test_rq", auto_start=False
    )

    # åˆ›å»ºç›¸åŒå†…å®¹çš„æ¶ˆæ¯
    message1 = SimpleQueueItem(
        data={"id": "duplicate", "content": "Same content"}, item_type="duplicate_test"
    )
    message2 = SimpleQueueItem(
        data={"id": "duplicate", "content": "Same content"}, item_type="duplicate_test"
    )

    # æŠ•é€’åˆ°åŒä¸€ä¸ªåˆ†ç»„ï¼ˆä¼šæœ‰ç›¸åŒçš„scoreï¼‰
    success1 = await manager.deliver_message("dup_group", message1)
    success2 = await manager.deliver_message("dup_group", message2)

    # ç¬¬ä¸€æ¡åº”è¯¥æˆåŠŸï¼Œç¬¬äºŒæ¡å¯èƒ½å¤±è´¥ï¼ˆå–å†³äºscoreæ˜¯å¦å®Œå…¨ç›¸åŒï¼‰
    assert success1, "ç¬¬ä¸€æ¡æ¶ˆæ¯åº”è¯¥æŠ•é€’æˆåŠŸ"
    # æ³¨æ„ï¼šç”±äºä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºscoreï¼Œç¬¬äºŒæ¡æ¶ˆæ¯é€šå¸¸ä¹Ÿä¼šæˆåŠŸ
    # success2çš„ç»“æœå–å†³äºæ—¶é—´æˆ³ç²¾åº¦ï¼Œè¿™é‡Œä¸å¼ºåˆ¶æ–­è¨€
    _ = success2  # é¿å…æœªä½¿ç”¨å˜é‡è­¦å‘Š


async def test_large_message_handling(manager_factory):
    """æµ‹è¯•å¤§æ¶ˆæ¯å¤„ç†"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="large_msg_test_rq", auto_start=False
    )

    # åˆ›å»ºè¾ƒå¤§çš„æ¶ˆæ¯
    large_data = {"content": "x" * 10000, "id": "large_message"}
    large_message = SimpleQueueItem(data=large_data, item_type="large_test")

    success = await manager.deliver_message("large_group", large_message)
    assert success, "å¤§æ¶ˆæ¯åº”è¯¥èƒ½å¤ŸæŠ•é€’æˆåŠŸ"

    messages = await manager.get_messages(score_threshold=0)
    assert len(messages) >= 0, "åº”è¯¥èƒ½å¤Ÿå¤„ç†å¤§æ¶ˆæ¯"


# ==================== å¹¶å‘æµ‹è¯• ====================


async def test_concurrent_message_delivery(manager_factory):
    """æµ‹è¯•å¹¶å‘æ¶ˆæ¯æŠ•é€’"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="concurrent_delivery_rq", auto_start=False
    )

    async def deliver_messages(group_prefix: str, count: int):
        for i in range(count):
            message = SimpleQueueItem(
                data={
                    "id": f"{group_prefix}_{i}",
                    "content": f"Concurrent message {i}",
                },
                item_type="concurrent_test",
            )
            await manager.deliver_message(f"{group_prefix}_group_{i}", message)

    # å¹¶å‘æŠ•é€’æ¶ˆæ¯
    tasks = [
        deliver_messages("concurrent_1", 10),
        deliver_messages("concurrent_2", 10),
        deliver_messages("concurrent_3", 10),
    ]

    await asyncio.gather(*tasks)

    # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
    stats = await manager.get_manager_stats()
    # ç”±äºå¹¶å‘å’Œå¯èƒ½çš„é‡å¤æ¶ˆæ¯ï¼Œæˆ‘ä»¬å…è®¸ä¸€å®šçš„è¯¯å·®
    assert (
        stats["total_delivered_messages"] >= 28
    ), f"åº”è¯¥æŠ•é€’å¤§éƒ¨åˆ†æ¶ˆæ¯ï¼Œå®é™…æŠ•é€’äº†{stats['total_delivered_messages']}æ¡"


async def test_concurrent_consumer_operations(manager_factory):
    """æµ‹è¯•å¹¶å‘æ¶ˆè´¹è€…æ“ä½œ"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="concurrent_consumer_test_rq",  # ä½¿ç”¨ç‹¬ç‰¹çš„å‰ç¼€é¿å…å†²çª
        auto_start=False,
    )

    # å…ˆæ¸…ç†æ‰€æœ‰æ¶ˆè´¹è€…ï¼Œç¡®ä¿å¹²å‡€çš„ç¯å¢ƒ
    await manager.force_cleanup_and_reset()

    async def consumer_lifecycle(consumer_id: str):
        try:
            # åŠ å…¥æ¶ˆè´¹è€…
            await manager.join_consumer(consumer_id)
            await asyncio.sleep(0.1)

            # ä¿æ´»
            await manager.keepalive_consumer(consumer_id)
            await asyncio.sleep(0.1)

            # é€€å‡º
            await manager.exit_consumer(consumer_id)
        except Exception as e:
            print(f"æ¶ˆè´¹è€… {consumer_id} ç”Ÿå‘½å‘¨æœŸå¼‚å¸¸: {e}")

    # å¹¶å‘æ‰§è¡Œæ¶ˆè´¹è€…ç”Ÿå‘½å‘¨æœŸ
    tasks = [consumer_lifecycle(f"concurrent_consumer_{i}") for i in range(5)]
    await asyncio.gather(*tasks, return_exceptions=True)

    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿æ‰€æœ‰æ“ä½œå®Œæˆ
    await asyncio.sleep(0.5)

    # éªŒè¯æœ€ç»ˆçŠ¶æ€
    owners = await manager.redis_client.zrange(
        manager.owner_activate_time_zset_key, 0, -1
    )
    # ç”±äºå¹¶å‘æ“ä½œçš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬å…è®¸ä¸€äº›æ¶ˆè´¹è€…å¯èƒ½è¿˜æ²¡å®Œå…¨é€€å‡º
    # ä½†åº”è¯¥å¤§éƒ¨åˆ†éƒ½é€€å‡ºäº†
    assert (
        len(owners) <= 2
    ), f"å¤§éƒ¨åˆ†æ¶ˆè´¹è€…éƒ½åº”è¯¥å·²é€€å‡ºï¼Œä½†è¿˜å‰©{len(owners)}ä¸ª: {owners}"


# ==================== ç”Ÿå‘½å‘¨æœŸæµ‹è¯• ====================


async def test_manager_lifecycle(manager_factory):
    """æµ‹è¯•ç®¡ç†å™¨ç”Ÿå‘½å‘¨æœŸ"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="lifecycle_test_rq",  # ä½¿ç”¨ç‹¬ç‰¹çš„å‰ç¼€é¿å…å†²çª
        auto_start=False,  # æ‰‹åŠ¨æ§åˆ¶å¯åŠ¨
    )

    # å¯åŠ¨å®šæœŸä»»åŠ¡
    await manager.start()
    assert (
        manager._running
    ), "ç®¡ç†å™¨åº”è¯¥å¤„äºè¿è¡ŒçŠ¶æ€"  # pylint: disable=protected-access

    # å…ˆæ¸…ç†å¯èƒ½çš„æ®‹ç•™æ•°æ®
    await manager.force_cleanup_and_reset()

    # æŠ•é€’å’Œè·å–æ¶ˆæ¯
    sample_message = SimpleQueueItem(
        data={"user_id": "12345", "content": "Hello World", "timestamp": time.time()},
        item_type="chat_message",
    )
    await manager.deliver_message("lifecycle_group", sample_message)
    messages = await manager.get_messages(score_threshold=0)
    assert len(messages) == 1, f"åº”è¯¥èƒ½æ­£å¸¸å¤„ç†1æ¡æ¶ˆæ¯ï¼Œä½†è·å–åˆ°{len(messages)}æ¡æ¶ˆæ¯"

    # è½¯å…³é—­ï¼ˆæœ‰æ¶ˆæ¯æ—¶åº”è¯¥å¤±è´¥ï¼‰
    await manager.deliver_message("lifecycle_group_2", sample_message)
    success = await manager.shutdown(ShutdownMode.SOFT)
    # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½æˆåŠŸä¹Ÿå¯èƒ½å¤±è´¥ï¼Œå–å†³äºæ¶ˆæ¯æ˜¯å¦è¢«æ¶ˆè´¹

    # ç¡¬å…³é—­ï¼ˆåº”è¯¥æ€»æ˜¯æˆåŠŸï¼‰
    success = await manager.shutdown(ShutdownMode.HARD)
    assert success, "ç¡¬å…³é—­åº”è¯¥æ€»æ˜¯æˆåŠŸ"
    assert (
        not manager._running
    ), "ç®¡ç†å™¨åº”è¯¥åœæ­¢è¿è¡Œ"  # pylint: disable=protected-access


async def test_periodic_tasks_behavior(manager_factory):
    """æµ‹è¯•å®šæœŸä»»åŠ¡è¡Œä¸º"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="periodic_test_manager", auto_start=False  # æ‰‹åŠ¨æ§åˆ¶å¯åŠ¨
    )

    # å¯åŠ¨å®šæœŸä»»åŠ¡
    await manager.start_periodic_tasks()

    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©å®šæœŸä»»åŠ¡è¿è¡Œ
    await asyncio.sleep(0.5)

    # éªŒè¯ä»»åŠ¡æ­£åœ¨è¿è¡Œ  # pylint: disable=protected-access
    assert manager._running
    assert manager._log_task is not None
    assert manager._cleanup_task is not None
    # æ³¨æ„: keepalive æ˜¯æŒ‰éœ€è§¦å‘çš„ï¼Œä¸æ˜¯å®šæœŸä»»åŠ¡ï¼Œæ‰€ä»¥æ²¡æœ‰ _keepalive_task

    # åœæ­¢ä»»åŠ¡
    await manager.stop_periodic_tasks()
    assert not manager._running  # pylint: disable=protected-access


async def test_invalid_message_data_handling(manager_factory):
    """æµ‹è¯•æ— æ•ˆæ¶ˆæ¯æ•°æ®å¤„ç†"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="invalid_data_test_manager", auto_start=False
    )

    # åˆ›å»ºåŒ…å«æ— æ•ˆæ•°æ®çš„æ¶ˆæ¯
    invalid_message = SimpleQueueItem(
        data={"invalid": float('inf')}, item_type="invalid_test"  # JSONæ— æ³•åºåˆ—åŒ–çš„æ•°æ®
    )

    # å°è¯•æŠ•é€’ï¼ˆåº”è¯¥å¤„ç†åºåˆ—åŒ–é”™è¯¯ï¼‰
    try:
        success = await manager.deliver_message("invalid_group", invalid_message)
        # å¦‚æœæ²¡æœ‰æŠ›å‡ºå¼‚å¸¸ï¼Œæ£€æŸ¥æ˜¯å¦æ­£ç¡®å¤„ç†
        assert isinstance(success, bool)
    except (ValueError, TypeError):
        # é¢„æœŸçš„åºåˆ—åŒ–é”™è¯¯
        pass


# ==================== æ€§èƒ½æµ‹è¯• ====================


async def test_high_throughput_delivery(manager_factory):
    """æµ‹è¯•é«˜ååé‡æŠ•é€’"""
    manager = await manager_factory.get_manager_with_config(
        key_prefix="throughput_test_rq", auto_start=False
    )

    start_time = time.time()

    # æŠ•é€’å¤§é‡æ¶ˆæ¯
    message_count = 100
    for i in range(message_count):
        message = SimpleQueueItem(
            data={"id": i, "content": f"Throughput test {i}"},
            item_type="throughput_test",
        )
        await manager.deliver_message(f"throughput_group_{i % 10}", message)

    end_time = time.time()
    duration = end_time - start_time

    # éªŒè¯æ€§èƒ½ï¼ˆè¿™ä¸ªé˜ˆå€¼å¯èƒ½éœ€è¦æ ¹æ®å®é™…ç¯å¢ƒè°ƒæ•´ï¼‰
    throughput = message_count / duration
    print(f"æŠ•é€’ååé‡: {throughput:.2f} messages/second")

    # éªŒè¯æ‰€æœ‰æ¶ˆæ¯éƒ½è¢«æŠ•é€’
    stats = await manager.get_manager_stats()
    # ç”±äºå¯èƒ½çš„é‡å¤æ¶ˆæ¯æˆ–å†²çªï¼Œæˆ‘ä»¬å…è®¸ä¸€å®šçš„è¯¯å·®
    assert (
        stats["total_delivered_messages"] >= message_count * 0.9
    ), f"åº”è¯¥æŠ•é€’å¤§éƒ¨åˆ†æ¶ˆæ¯ï¼ŒæœŸæœ›{message_count}ï¼Œå®é™…{stats['total_delivered_messages']}"


# ==================== è¾…åŠ©å‡½æ•° ====================


def create_test_message(message_id: str, content: str = None) -> SimpleQueueItem:
    """åˆ›å»ºæµ‹è¯•æ¶ˆæ¯"""
    return SimpleQueueItem(
        data={
            "id": message_id,
            "content": content or f"Test message {message_id}",
            "timestamp": time.time(),
        },
        item_type="test_message",
    )


# ==================== è¿è¡Œæµ‹è¯• ====================


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹è¿è¡ŒRedisæ¶ˆæ¯åˆ†ç»„é˜Ÿåˆ—ç®¡ç†å™¨ç»¼åˆæµ‹è¯•...")

    if not IMPORTS_AVAILABLE:
        print("âŒ æ— æ³•å¯¼å…¥å¿…è¦çš„æ¨¡å—ï¼Œè¯·ç¡®ä¿é¡¹ç›®ä¾èµ–å·²æ­£ç¡®å®‰è£…")
        print("è¯·å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š")
        print(
            "1. ä½¿ç”¨ bootstrap æ–¹å¼è¿è¡Œ: python src/bootstrap.py tests/test_redis_group_queue_manager_comprehensive.py"
        )
        print("2. ç¡®ä¿æ‰€æœ‰ä¾èµ–å·²å®‰è£…: pip install -r requirements.txt")
        print("3. æ£€æŸ¥ç¯å¢ƒå˜é‡å’ŒPythonè·¯å¾„è®¾ç½®")
        return

    try:
        from core.di.utils import get_bean_by_type
        from core.queue.redis_group_queue.redis_msg_group_queue_manager_factory import (
            RedisGroupQueueManagerFactory,
        )
        from component.redis_provider import RedisProvider

        # è·å–ç®¡ç†å™¨å·¥å‚å®ä¾‹
        manager_factory = get_bean_by_type(RedisGroupQueueManagerFactory)
        # è·å–Redisæä¾›è€…ï¼Œç”¨äºæ¸…ç†æ•°æ®åº“
        redis_provider = get_bean_by_type(RedisProvider)

    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥ä¾èµ–æ³¨å…¥æ¨¡å—: {e}")
        print("è¯·ç¡®ä¿é¡¹ç›®å·²æ­£ç¡®åˆå§‹åŒ–å¹¶ä¸”ä¾èµ–æ³¨å…¥å®¹å™¨å·²è®¾ç½®")
        return
    except Exception as e:
        print(f"âŒ è·å–ç®¡ç†å™¨å·¥å‚å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿RedisæœåŠ¡æ­£åœ¨è¿è¡Œå¹¶ä¸”é…ç½®æ­£ç¡®")
        return

    # å®šä¹‰æ‰€æœ‰æµ‹è¯•å‡½æ•°
    tests = [
        test_basic_message_delivery_and_retrieval,
        test_score_logic_with_old_timestamps,
        test_message_delivery_limit,
        test_queue_statistics,
        test_improved_stats_functionality,
        test_stats_performance_and_accuracy,
        test_stats_error_handling,
        test_group_key_routing_consistency,
        test_group_key_distribution,
        test_score_threshold_filtering,
        test_single_message_queue_boundary_case,
        test_out_of_order_insertion_ordered_retrieval,
        test_consumer_join_and_exit,
        test_consumer_keepalive,
        test_automatic_consumer_join_on_get_messages,
        test_rebalance_partitions,
        test_rebalance_with_uneven_partitions,
        test_cleanup_inactive_owners,
        test_force_cleanup_and_reset,
        test_empty_queue_operations,
        test_nonexistent_consumer_operations,
        test_duplicate_message_handling,
        test_large_message_handling,
        test_concurrent_message_delivery,
        test_concurrent_consumer_operations,
        test_manager_lifecycle,
        test_periodic_tasks_behavior,
        test_invalid_message_data_handling,
        test_high_throughput_delivery,
    ]

    passed = 0
    failed = 0

    # è·å–Rediså®¢æˆ·ç«¯ç”¨äºæ¸…ç†
    redis_client = await redis_provider.get_named_client(
        "default", decode_responses=True
    )

    # é‡å¯æ—¶å…ˆæ¸…ç†æ•°æ®åº“
    try:
        await redis_client.flushdb()
        print("ğŸ§¹ å¯åŠ¨æ—¶Redisæ•°æ®åº“å·²æ¸…ç†")
    except Exception as e:
        print(f"âš ï¸ å¯åŠ¨æ—¶æ¸…ç†Redisæ•°æ®åº“å¤±è´¥: {e}")
        return

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    for test_func in tests:
        print(f"\nè¿è¡Œæµ‹è¯•: {test_func.__name__}")
        print("-" * 50)

        # æµ‹è¯•å‰æ¸…ç†Redisæ•°æ®åº“
        try:
            await redis_client.flushdb()
            print("ğŸ§¹ Redisæ•°æ®åº“å·²æ¸…ç†")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†Redisæ•°æ®åº“å¤±è´¥: {e}")

        try:
            await test_func(manager_factory)
            print(f"âœ… {test_func.__name__} æµ‹è¯•é€šè¿‡")
            passed += 1
        except AssertionError as e:
            print(f"âŒ {test_func.__name__} æµ‹è¯•å¤±è´¥: {str(e)}")
            failed += 1
            traceback.print_exc()
            # ä»»æ„å¤±è´¥ç›´æ¥æ¸…ç†é€€å‡º
            print("ğŸ’¥ æ£€æµ‹åˆ°æµ‹è¯•å¤±è´¥ï¼Œå¼€å§‹æ¸…ç†å¹¶é€€å‡º...")
            break
        except Exception as e:
            print(f"âŒ {test_func.__name__} æµ‹è¯•å‡ºé”™: {str(e)}")
            failed += 1
            traceback.print_exc()
            # ä»»æ„å¤±è´¥ç›´æ¥æ¸…ç†é€€å‡º
            print("ğŸ’¥ æ£€æµ‹åˆ°æµ‹è¯•å‡ºé”™ï¼Œå¼€å§‹æ¸…ç†å¹¶é€€å‡º...")
            break

        # æµ‹è¯•ååœæ­¢æ‰€æœ‰ç®¡ç†å™¨çš„å®šæœŸä»»åŠ¡ï¼Œé¿å…ä¿æ´»è­¦å‘Š
        try:
            await manager_factory.stop_all_managers()
            print("ğŸ”Œ æµ‹è¯•åæ‰€æœ‰ç®¡ç†å™¨å·²åœæ­¢")
        except Exception as e:
            print(f"âš ï¸ åœæ­¢ç®¡ç†å™¨å¤±è´¥: {e}")

        # æµ‹è¯•åæ¸…ç†Redisæ•°æ®åº“
        try:
            await redis_client.flushdb()
            print("ğŸ§¹ æµ‹è¯•åRedisæ•°æ®åº“å·²æ¸…ç†")
        except Exception as e:
            print(f"âš ï¸ æµ‹è¯•åæ¸…ç†Redisæ•°æ®åº“å¤±è´¥: {e}")

        # çŸ­æš‚ç­‰å¾…ï¼Œç¡®ä¿å¼‚æ­¥ä»»åŠ¡å®Œå…¨åœæ­¢
        await asyncio.sleep(0.1)

    print(f"\næµ‹è¯•ç»“æœ: {passed} é€šè¿‡, {failed} å¤±è´¥")

    # æ¸…ç†æ‰€æœ‰ç®¡ç†å™¨
    await manager_factory.stop_all_managers()
    print("ğŸ”Œ æ‰€æœ‰ç®¡ç†å™¨å·²åœæ­¢")

    # æœ€ç»ˆæ¸…ç†Redisæ•°æ®åº“
    try:
        await redis_client.flushdb()
        print("ğŸ§¹ æœ€ç»ˆRedisæ•°æ®åº“æ¸…ç†å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ æœ€ç»ˆæ¸…ç†Redisæ•°æ®åº“å¤±è´¥: {e}")
    finally:
        await redis_client.close()
        print("ğŸ”Œ Redisè¿æ¥å·²å…³é—­")


if __name__ == "__main__":
    asyncio.run(run_all_tests())
