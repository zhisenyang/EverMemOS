#!/usr/bin/env python3
"""
ä¸“é—¨æµ‹è¯•conv_memcellå’Œepisode_memoryæå–çš„æµ‹è¯•æ–‡ä»¶
ä½¿ç”¨testsæ–‡ä»¶å¤¹ä¸‹çš„928_group.jsonæ•°æ®
"""

import asyncio
import json
import sys
import os
import pickle
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

from memory_layer.types import RawDataType, MemCell
from memory_layer.memcell_extractor.base_memcell_extractor import RawData
from memory_layer.memcell_extractor.conv_memcell_extractor import (
    ConvMemCellExtractor,
    ConversationMemCellExtractRequest,
)
from memory_layer.memory_extractor.episode_memory_extractor import (
    EpisodeMemoryExtractor,
    EpisodeMemoryExtractRequest,
)
from memory_layer.llm.openai_provider import OpenAIProvider


class TestConvMemcellEpisodeExtraction:
    """ä¸“é—¨æµ‹è¯•conv_memcellå’Œepisode_memoryæå–çš„æµ‹è¯•ç±»"""

    def __init__(self):
        self.llm_provider = OpenAIProvider()
        self.conv_extractor = ConvMemCellExtractor(self.llm_provider)
        self.episode_extractor = EpisodeMemoryExtractor(self.llm_provider)

        # MemCellç¼“å­˜ç›®å½•
        self.cache_dir = Path(__file__).parent / "memcell_cache"
        self.cache_dir.mkdir(exist_ok=True)

    def save_memcells_to_file(
        self,
        memcells: List[MemCell],
        episode_memories: List = None,
        filename: str = None,
    ) -> str:
        """ä¿å­˜MemCellåˆ—è¡¨å’ŒEpisodeMemoryåˆ°æœ¬åœ°æ–‡ä»¶"""
        if filename is None:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªMemCellçš„event_idå’Œæ—¶é—´æˆ³ä½œä¸ºæ–‡ä»¶å
            if memcells and len(memcells) > 0:
                first_memcell = memcells[0]
                event_id = first_memcell.event_id[:8]  # å–å‰8ä½é¿å…æ–‡ä»¶åè¿‡é•¿
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{event_id}_{timestamp}.json"
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"memcells_{timestamp}.json"

        # ç¡®ä¿æ–‡ä»¶åæ˜¯JSONæ ¼å¼
        if not filename.endswith('.json'):
            filename = filename.replace('.pkl', '.json')

        cache_file = self.cache_dir / filename

        try:
            # å°†MemCellè½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼
            memcells_json = []
            for memcell in memcells:
                memcell_dict = {
                    "event_id": memcell.event_id,
                    "user_id_list": memcell.user_id_list,
                    "original_data": memcell.original_data,
                    "timestamp": memcell.timestamp,
                    "summary": memcell.summary,
                    "group_id": memcell.group_id,
                    "participants": memcell.participants,
                    "type": memcell.type.value if memcell.type else None,
                    "keywords": memcell.keywords,
                    "subject": memcell.subject,
                    "linked_entities": memcell.linked_entities,
                    "episode": memcell.episode,
                }
                memcells_json.append(memcell_dict)

            # å°†EpisodeMemoryè½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼
            episode_memories_json = []
            if episode_memories:
                for memory in episode_memories:
                    memory_dict = {
                        "memory_type": (
                            memory.memory_type.value
                            if hasattr(memory.memory_type, 'value')
                            else str(memory.memory_type)
                        ),
                        "event_id": memory.event_id,
                        "user_id": memory.user_id,
                        "timestamp": memory.timestamp,
                        "ori_event_id": memory.ori_event_id,
                        "title": memory.title,
                        "summary": memory.summary,
                        "tags": memory.tags,
                        "group_id": memory.group_id,
                        "participants": memory.participants,
                        "type": memory.type,
                    }
                    episode_memories_json.append(memory_dict)

            # ç»„åˆæ•°æ®
            save_data = {
                "memcells": memcells_json,
                "episode_memories": episode_memories_json,
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "memcell_count": len(memcells),
                    "episode_memory_count": (
                        len(episode_memories) if episode_memories else 0
                    ),
                },
            }

            # ä¿å­˜ä¸ºJSONæ–‡ä»¶
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ æˆåŠŸä¿å­˜åˆ°: {cache_file}")
            print(f"   MemCellæ•°é‡: {len(memcells)}")
            print(
                f"   EpisodeMemoryæ•°é‡: {len(episode_memories) if episode_memories else 0}"
            )
            print(f"   æ–‡ä»¶å¤§å°: {cache_file.stat().st_size / 1024:.2f} KB")
            print(f"   æ ¼å¼: JSON (ä¾¿äºæŸ¥çœ‹å’Œç¼–è¾‘)")

            return str(cache_file)

        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return None

    def load_memcells_from_file(self, filename: str) -> tuple[List[MemCell], List]:
        """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½MemCellåˆ—è¡¨å’ŒEpisodeMemory"""
        cache_file = self.cache_dir / filename

        if not cache_file.exists():
            print(f"âŒ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {cache_file}")
            return [], []

        try:
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŠ è½½æ–¹å¼
            if filename.endswith('.json'):
                # åŠ è½½JSONæ ¼å¼
                with open(cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ ¼å¼ï¼ˆåŒ…å«memcellså’Œepisode_memoriesï¼‰
                if isinstance(data, dict) and 'memcells' in data:
                    # æ–°æ ¼å¼
                    memcells_data = data.get('memcells', [])
                    episode_memories_data = data.get('episode_memories', [])
                    metadata = data.get('metadata', {})

                    print(f"ğŸ“‚ åŠ è½½æ–°æ ¼å¼æ•°æ®:")
                    print(f"   åˆ›å»ºæ—¶é—´: {metadata.get('created_at', 'æœªçŸ¥')}")
                    print(
                        f"   MemCellæ•°é‡: {metadata.get('memcell_count', len(memcells_data))}"
                    )
                    print(
                        f"   EpisodeMemoryæ•°é‡: {metadata.get('episode_memory_count', len(episode_memories_data))}"
                    )
                else:
                    # æ—§æ ¼å¼ï¼ˆç›´æ¥æ˜¯MemCellåˆ—è¡¨ï¼‰
                    memcells_data = data if isinstance(data, list) else [data]
                    episode_memories_data = []

                # å°†JSONæ•°æ®è½¬æ¢å›MemCellå¯¹è±¡
                memcells = []
                for data_item in memcells_data:
                    # å¤„ç†typeå­—æ®µ
                    type_value = None
                    if data_item.get('type'):
                        type_value = RawDataType(data_item['type'])

                    memcell = MemCell(
                        event_id=data_item['event_id'],
                        user_id_list=data_item['user_id_list'],
                        original_data=data_item['original_data'],
                        timestamp=data_item['timestamp'],
                        summary=data_item['summary'],
                        group_id=data_item.get('group_id'),
                        participants=data_item.get('participants'),
                        type=type_value,
                        keywords=data_item.get('keywords'),
                        subject=data_item.get('subject'),
                        linked_entities=data_item.get('linked_entities'),
                        episode=data_item.get('episode'),
                    )
                    memcells.append(memcell)

                # å°†JSONæ•°æ®è½¬æ¢å›EpisodeMemoryå¯¹è±¡ï¼ˆè¿™é‡Œåªè¿”å›åŸå§‹æ•°æ®ï¼Œä¸è½¬æ¢ä¸ºå¯¹è±¡ï¼‰
                episode_memories = episode_memories_data

            else:
                # å…¼å®¹æ—§çš„pickleæ ¼å¼
                with open(cache_file, 'rb') as f:
                    data = pickle.load(f)
                    if isinstance(data, list):
                        memcells = data
                        episode_memories = []
                    else:
                        memcells = [data]
                        episode_memories = []

            print(f"ğŸ“‚ æˆåŠŸåŠ è½½ä»: {cache_file}")
            print(f"   æ–‡ä»¶å¤§å°: {cache_file.stat().st_size / 1024:.2f} KB")
            print(f"   æ ¼å¼: {'JSON' if filename.endswith('.json') else 'Pickle'}")
            print(f"   MemCellæ•°é‡: {len(memcells)}")
            print(f"   EpisodeMemoryæ•°é‡: {len(episode_memories)}")

            # æ˜¾ç¤ºåŠ è½½çš„MemCellæ‘˜è¦
            for i, memcell in enumerate(memcells):
                print(f"   ğŸ“ MemCell #{i+1}: {memcell.summary[:50]}...")

            return memcells, episode_memories

        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return [], []

    def list_cached_files(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰ç¼“å­˜çš„MemCellæ–‡ä»¶"""
        # æŸ¥æ‰¾JSONå’Œpickleæ–‡ä»¶
        json_files = list(self.cache_dir.glob("*.json"))
        pkl_files = list(self.cache_dir.glob("*.pkl"))

        # è¿‡æ»¤æ‰æ‘˜è¦æ–‡ä»¶ï¼ˆå¦‚æœJSONæ–‡ä»¶ååŒ…å«streaming_testç­‰ï¼Œè¯´æ˜æ˜¯ä¸»æ–‡ä»¶ï¼‰
        main_json_files = [
            f for f in json_files if 'streaming_test' in f.name or 'memcells_' in f.name
        ]
        all_files = main_json_files + pkl_files

        if not all_files:
            print("ğŸ“ ç¼“å­˜ç›®å½•ä¸ºç©ºï¼Œæ²¡æœ‰æ‰¾åˆ°MemCellæ–‡ä»¶")
            return []

        print(f"ğŸ“ æ‰¾åˆ° {len(all_files)} ä¸ªMemCellç¼“å­˜æ–‡ä»¶:")
        files = []
        for cache_file in sorted(
            all_files, key=lambda f: f.stat().st_mtime, reverse=True
        ):
            file_size = cache_file.stat().st_size / 1024
            mod_time = datetime.fromtimestamp(cache_file.stat().st_mtime)
            file_format = "JSON" if cache_file.suffix == '.json' else "Pickle"

            # è·å–MemCellæ•°é‡
            memcell_count = "æœªçŸ¥"
            try:
                if cache_file.suffix == '.json':
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        memcell_count = len(data)
                else:
                    # å¯¹äºpickleæ–‡ä»¶ï¼Œå°è¯•å¿«é€Ÿè®¡ç®—
                    with open(cache_file, 'rb') as f:
                        data = pickle.load(f)
                        memcell_count = len(data) if isinstance(data, list) else 1
            except:
                pass

            print(f"   ğŸ“„ {cache_file.name}")
            print(
                f"      æ ¼å¼: {file_format} | å¤§å°: {file_size:.2f} KB | MemCellæ•°: {memcell_count} | ä¿®æ”¹æ—¶é—´: {mod_time.strftime('%Y-%m-%d %H:%M:%S')}"
            )
            files.append(cache_file.name)

        return files

    def load_928_group_data(self) -> List[Dict[str, Any]]:
        """åŠ è½½928_group.jsonæ•°æ®"""
        json_file = Path(__file__).parent / "928_group.json"
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        print(f"ğŸ“š åŠ è½½äº† {len(data)} æ¡æ¶ˆæ¯æ•°æ®")
        return data

    def convert_to_raw_data(
        self, messages: List[Dict[str, Any]], start_idx: int = 0, count: int = 10
    ) -> List[RawData]:
        """å°†JSONæ¶ˆæ¯è½¬æ¢ä¸ºRawDataæ ¼å¼"""
        raw_data_list = []

        # å–æŒ‡å®šèŒƒå›´çš„æ¶ˆæ¯
        selected_messages = messages[start_idx : start_idx + count]

        for msg in selected_messages:
            # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯
            if 'sender' not in msg or not msg.get('content'):
                continue

            # è½¬æ¢æ—¶é—´æ ¼å¼
            create_time = msg.get('createTime', '')
            if create_time:
                try:
                    # ä¿æŒISOæ—¶é—´æ ¼å¼ï¼Œä¾›è¾¹ç•Œæ£€æµ‹ä½¿ç”¨
                    timestamp_str = create_time
                    # ä¹Ÿè®¡ç®—timestampç”¨äºå…¶ä»–åœ°æ–¹
                    dt = datetime.fromisoformat(create_time.replace('Z', '+00:00'))
                    timestamp = int(dt.timestamp())
                except:
                    timestamp_str = datetime.now().isoformat()
                    timestamp = int(datetime.now().timestamp())
            else:
                timestamp_str = datetime.now().isoformat()
                timestamp = int(datetime.now().timestamp())

            content = {
                "content": msg.get('content', ''),
                "sender": msg.get('sender', ''),
                "timestamp": timestamp_str,  # ä½¿ç”¨ISOæ ¼å¼å­—ç¬¦ä¸²
                "sender_title": msg.get('sender_title', ''),
                "tanka_mag_id": msg.get('tanka_mag_id', ''),
            }

            raw_data = RawData(
                content=content,
                data_id=msg.get(
                    'tanka_mag_id', f'msg_{start_idx + len(raw_data_list)}'
                ),
            )
            raw_data_list.append(raw_data)

        print(f"âœ… è½¬æ¢äº† {len(raw_data_list)} æ¡æ¶ˆæ¯ä¸ºRawData")
        return raw_data_list

    async def test_conv_memcell_extraction(
        self, raw_data_list: List[RawData]
    ) -> MemCell:
        """æµ‹è¯•å¯¹è¯è¾¹ç•Œæ£€æµ‹å’ŒMemCellæå–"""
        print("\n" + "=" * 80)
        print("ğŸ§ª æµ‹è¯•ConvMemCellExtraction - å¯¹è¯è¾¹ç•Œæ£€æµ‹")
        print("=" * 80)

        if len(raw_data_list) < 5:
            print("âŒ æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘5æ¡æ¶ˆæ¯")
            return None

        # åˆ†å‰²å†å²å’Œæ–°æ¶ˆæ¯
        history_raw_data_list = raw_data_list[:-3]  # å‰é¢çš„ä½œä¸ºå†å²
        new_raw_data_list = raw_data_list[-3:]  # æœ€å3æ¡ä½œä¸ºæ–°æ¶ˆæ¯

        participants = []
        for data in raw_data_list:
            sender = data.content.get('sender', '')
            if sender and sender not in participants:
                participants.append(sender)

        print(f"ğŸ“Š å†å²æ¶ˆæ¯: {len(history_raw_data_list)} æ¡")
        print(f"ğŸ“Š æ–°æ¶ˆæ¯: {len(new_raw_data_list)} æ¡")
        print(f"ğŸ‘¥ å‚ä¸è€…: {participants}")

        # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹
        print("\nğŸ’¬ å†å²æ¶ˆæ¯é¢„è§ˆ:")
        for i, data in enumerate(history_raw_data_list[-3:]):  # åªæ˜¾ç¤ºæœ€å3æ¡å†å²æ¶ˆæ¯
            content = data.content.get('content', '')[:100]
            sender = data.content.get('sender', '')
            print(f"   [{i+1}] {sender}: {content}...")

        print("\nğŸ’¬ æ–°æ¶ˆæ¯é¢„è§ˆ:")
        for i, data in enumerate(new_raw_data_list):
            content = data.content.get('content', '')[:100]
            sender = data.content.get('sender', '')
            print(f"   [{i+1}] {sender}: {content}...")

        # åˆ›å»ºè¯·æ±‚
        request = ConversationMemCellExtractRequest(
            history_raw_data_list=history_raw_data_list,
            new_raw_data_list=new_raw_data_list,
            user_id_list=participants,
            participants=participants,
            group_id="928_group_test",
            old_memory_list=[],
        )

        print(f"\nğŸ”„ æ‰§è¡Œå¯¹è¯è¾¹ç•Œæ£€æµ‹...")
        try:
            result = await self.conv_extractor.extract_memcell(request)

            if result is None:
                print("âŒ extract_memcellè¿”å›None")
                return None

            if isinstance(result, tuple):
                if len(result) == 2:
                    memcell, status_result = result
                elif len(result) == 3:
                    memcell, status_result, episode_memories = result
                else:
                    print(f"âŒ æ„å¤–çš„è¿”å›å€¼æ ¼å¼: {len(result)} ä¸ªå…ƒç´ ")
                    return None
            else:
                memcell = result
                status_result = None

            print(f"\nğŸ“‹ è¾¹ç•Œæ£€æµ‹ç»“æœ:")
            if status_result:
                print(f"   should_wait: {status_result.should_wait}")

            if memcell:
                print(f"âœ… æˆåŠŸæå–MemCell:")
                print(f"   event_id: {memcell.event_id}")
                print(f"   user_id_list: {memcell.user_id_list}")
                print(f"   participants: {memcell.participants}")
                print(f"   summary: {memcell.summary[:200]}...")
                print(f"   timestamp: {memcell.timestamp}")
                print(f"   group_id: {memcell.group_id}")
                return memcell
            else:
                print("â„¹ï¸ æœªæ£€æµ‹åˆ°å¯¹è¯è¾¹ç•Œï¼Œæ²¡æœ‰ç”ŸæˆMemCell")
                return None

        except Exception as e:
            print(f"âŒ ConvMemCellæå–å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return None

    async def test_episode_memory_extraction(self, memcell: MemCell) -> None:
        """æµ‹è¯•æƒ…æ™¯è®°å¿†æå–"""
        print("\n" + "=" * 80)
        print("ğŸ§ª æµ‹è¯•EpisodeMemoryExtraction - æƒ…æ™¯è®°å¿†æå–")
        print("=" * 80)

        if not memcell:
            print("âŒ æ²¡æœ‰MemCellï¼Œè·³è¿‡æƒ…æ™¯è®°å¿†æå–æµ‹è¯•")
            return

        # ä»MemCellçš„åŸå§‹æ•°æ®ä¸­æå–å‚ä¸è€…åˆ—è¡¨ä½œä¸ºuser_id_list
        conversation_participants = []
        if hasattr(memcell, 'original_data') and memcell.original_data:
            for data in memcell.original_data:
                sender = data.get('sender', '')
                if sender and sender not in conversation_participants:
                    conversation_participants.append(sender)

        # å¦‚æœä»åŸå§‹æ•°æ®æå–å¤±è´¥ï¼Œåˆ™ä½¿ç”¨memcellçš„user_id_listä½œä¸ºåå¤‡
        if not conversation_participants:
            conversation_participants = memcell.user_id_list or []

        print(f"ğŸ“Š ä»å¯¹è¯ä¸­æå–çš„å‚ä¸è€…: {conversation_participants}")

        # åˆ›å»ºè¯·æ±‚
        request = EpisodeMemoryExtractRequest(
            memcell_list=[memcell],
            user_id_list=conversation_participants,  # ç›´æ¥ä»å¯¹è¯ä¸­æå–
            participants=memcell.participants,
            group_id=memcell.group_id,
            old_memory_list=[],
        )

        print(f"ğŸ”„ æ‰§è¡Œæƒ…æ™¯è®°å¿†æå–...")
        print(f"   MemCellæ•°é‡: {len(request.memcell_list)}")
        print(f"   å‚ä¸è€…: {request.participants}")
        print(f"   ç¾¤ç»„ID: {request.group_id}")

        try:
            episode_memories = await self.episode_extractor.extract_memory(request)

            if episode_memories:
                print(f"\nâœ… æˆåŠŸæå– {len(episode_memories)} ä¸ªæƒ…æ™¯è®°å¿†:")
                for i, memory in enumerate(episode_memories):
                    print(f"\n   ğŸ“ æƒ…æ™¯è®°å¿† #{i+1}:")
                    print(f"      event_id: {memory.event_id}")
                    print(f"      user_id: {memory.user_id}")
                    print(f"      title: {memory.title}")
                    print(f"      summary: {memory.summary[:200]}...")
                    print(f"      timestamp: {memory.timestamp}")
                    print(f"      memory_type: {memory.memory_type}")
                    if hasattr(memory, 'tags') and memory.tags:
                        print(f"      tags: {memory.tags}")
            else:
                print("â„¹ï¸ æ²¡æœ‰æå–åˆ°æƒ…æ™¯è®°å¿†")

        except Exception as e:
            print(f"âŒ æƒ…æ™¯è®°å¿†æå–å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()

    async def run_streaming_test(self, start_idx: int = 0, max_messages: int = 30):
        """è¿è¡Œæµå¼è¾“å…¥æµ‹è¯• - æ¨¡æ‹ŸçœŸå®å¯¹è¯åœºæ™¯"""
        print("ğŸš€ å¼€å§‹è¿è¡Œæµå¼å¯¹è¯è¾¹ç•Œæ£€æµ‹æµ‹è¯•")
        print("=" * 80)

        # 1. åŠ è½½æ•°æ®
        messages = self.load_928_group_data()
        all_raw_data = self.convert_to_raw_data(messages, start_idx, max_messages)

        if len(all_raw_data) < 5:
            print("âŒ è½¬æ¢åçš„æ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦5æ¡æœ‰æ•ˆæ¶ˆæ¯")
            return

        print(f"ğŸ“Š å‡†å¤‡æµå¼å¤„ç† {len(all_raw_data)} æ¡æ¶ˆæ¯")

        # æ¨¡æ‹Ÿæµå¼è¾“å…¥ï¼šç´¯ç§¯å†å²ï¼Œé€æ¡æ·»åŠ æ–°æ¶ˆæ¯
        history_buffer = []
        memcells_generated = []
        all_episode_memories = []  # æ”¶é›†æ‰€æœ‰ç”Ÿæˆçš„episode memories

        for i, new_raw_data in enumerate(all_raw_data):
            print(f"\n{'='*60}")
            print(f"ğŸ“¨ æµå¼è¾“å…¥ç¬¬ {i+1}/{len(all_raw_data)} æ¡æ¶ˆæ¯")
            print(f"{'='*60}")

            # æ˜¾ç¤ºå½“å‰æ¶ˆæ¯
            content = new_raw_data.content.get('content', '')[:100]
            sender = new_raw_data.content.get('sender', '')
            timestamp = new_raw_data.content.get('timestamp', '')
            print(f"ğŸ‘¤ {sender}: {content}...")
            print(f"â° æ—¶é—´: {timestamp}")

            # å¦‚æœå†å²æ¶ˆæ¯å°‘äº3æ¡ï¼Œå…ˆç§¯ç´¯å†å²
            if len(history_buffer) < 3:
                history_buffer.append(new_raw_data)
                print(f"ğŸ“š ç§¯ç´¯å†å²æ¶ˆæ¯ä¸­... ({len(history_buffer)}/3)")
                continue

            # å½“æœ‰è¶³å¤Ÿå†å²æ¶ˆæ¯æ—¶ï¼Œå¼€å§‹è¾¹ç•Œæ£€æµ‹
            print(f"ğŸ“Š å†å²æ¶ˆæ¯: {len(history_buffer)} æ¡")
            print(f"ğŸ“Š æ–°æ¶ˆæ¯: 1 æ¡")

            # è·å–å‚ä¸è€…
            participants = []
            for data in history_buffer + [new_raw_data]:
                sender = data.content.get('sender', '')
                if sender and sender not in participants:
                    participants.append(sender)

            print(f"ğŸ‘¥ å½“å‰å‚ä¸è€…: {participants}")

            # åˆ›å»ºè¯·æ±‚è¿›è¡Œè¾¹ç•Œæ£€æµ‹
            # ä¸ºäº†æµ‹è¯•participantsåˆå¹¶åŠŸèƒ½ï¼Œæˆ‘ä»¬æ•…æ„ä¼ å…¥ä¸€äº›é¢å¤–çš„participants
            test_participants = participants + [
                "Admin",
                "System",
            ]  # æ·»åŠ ä¸€äº›å¯èƒ½ä¸åœ¨å¯¹è¯ä¸­çš„å‚ä¸è€…

            request = ConversationMemCellExtractRequest(
                history_raw_data_list=history_buffer.copy(),
                new_raw_data_list=[new_raw_data],
                user_id_list=participants,
                participants=test_participants,  # ä½¿ç”¨æ‰©å±•çš„participantsåˆ—è¡¨
                group_id="928_group_streaming",
                old_memory_list=[],
            )

            print(f"ğŸ§ª æµ‹è¯•participantsåˆå¹¶åŠŸèƒ½:")
            print(f"   ä¼ å…¥çš„participants: {test_participants}")
            print(
                f"   å½“å‰å¯¹è¯ä¸­çš„speakers: {[d.content.get('sender', '') for d in history_buffer + [new_raw_data] if d.content.get('sender')]}"
            )
            print(f"   æœŸæœ›åˆå¹¶ç»“æœåº”åŒ…å«æ‰€æœ‰å”¯ä¸€çš„participantså’Œspeakers")

            print(f"ğŸ”„ æ‰§è¡Œè¾¹ç•Œæ£€æµ‹...")
            try:
                result = await self.conv_extractor.extract_memcell(request)

                if result is None:
                    print("âŒ extract_memcellè¿”å›None")
                    boundary_detected = False
                    memcell = None
                else:
                    if isinstance(result, tuple):
                        if len(result) == 2:
                            memcell, status_result = result
                        elif len(result) == 3:
                            memcell, status_result, episode_memories = result
                        else:
                            print(f"âŒ æ„å¤–çš„è¿”å›å€¼æ ¼å¼: {len(result)} ä¸ªå…ƒç´ ")
                            memcell = None
                            status_result = None
                    else:
                        memcell = result
                        status_result = None

                    print(f"ğŸ“‹ è¾¹ç•Œæ£€æµ‹ç»“æœ:")
                    if status_result:
                        print(f"   should_wait: {status_result.should_wait}")

                    if memcell:
                        boundary_detected = True
                        print(f"ğŸ¯ æ£€æµ‹åˆ°å¯¹è¯è¾¹ç•Œ! ç”ŸæˆMemCell:")
                        print(f"   event_id: {memcell.event_id}")
                        print(f"   summary: {memcell.summary[:100]}...")

                        memcells_generated.append(memcell)

                        # æµ‹è¯•Episode Memoryæå– - ä»å¯¹è¯ä¸­æå–user_id_list
                        print(f"ğŸ”„ è‡ªåŠ¨è§¦å‘æƒ…æ™¯è®°å¿†æå–...")

                        # ä»å†å²ç¼“å†²åŒºå’Œæ–°æ¶ˆæ¯ä¸­æå–æ‰€æœ‰å‚ä¸è€…ä½œä¸ºuser_id_list
                        conversation_participants = []
                        for data in history_buffer + [new_raw_data]:
                            sender = data.content.get('sender', '')
                            if sender and sender not in conversation_participants:
                                conversation_participants.append(sender)

                        print(f"ğŸ“Š ä»å¯¹è¯ä¸­æå–çš„å‚ä¸è€…: {conversation_participants}")

                        # åˆ›å»ºä¸“é—¨çš„Episode Memoryæå–è¯·æ±‚
                        episode_request = EpisodeMemoryExtractRequest(
                            memcell_list=[memcell],
                            user_id_list=conversation_participants,  # ç›´æ¥ä»å¯¹è¯ä¸­æå–
                            participants=participants,
                            group_id="928_group_streaming",
                            old_memory_list=[],
                        )

                        try:
                            episode_memories = (
                                await self.episode_extractor.extract_memory(
                                    episode_request
                                )
                            )
                            if episode_memories:
                                print(f"âœ… æˆåŠŸæå– {len(episode_memories)} ä¸ªæƒ…æ™¯è®°å¿†")
                                all_episode_memories.extend(
                                    episode_memories
                                )  # æ”¶é›†episode memories
                                for i, memory in enumerate(episode_memories):
                                    print(
                                        f"   ğŸ“ æƒ…æ™¯è®°å¿† #{i+1}: {memory.user_id} - {memory.title[:50]}..."
                                    )
                            else:
                                print("â„¹ï¸ æ²¡æœ‰æå–åˆ°æƒ…æ™¯è®°å¿†")
                        except Exception as e:
                            print(f"âŒ æƒ…æ™¯è®°å¿†æå–å¤±è´¥: {e}")

                        # æ¸…ç©ºå†å²ï¼Œé‡æ–°å¼€å§‹ç§¯ç´¯
                        print(f"ğŸ”„ é‡ç½®å†å²ç¼“å†²åŒºï¼Œå¼€å§‹æ–°çš„å¯¹è¯ç‰‡æ®µ")
                        history_buffer = []
                    else:
                        boundary_detected = False
                        print("â„¹ï¸ æœªæ£€æµ‹åˆ°å¯¹è¯è¾¹ç•Œï¼Œç»§ç»­ç§¯ç´¯å¯¹è¯")

            except Exception as e:
                print(f"âŒ è¾¹ç•Œæ£€æµ‹å¤±è´¥: {e}")
                boundary_detected = False

            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è¾¹ç•Œï¼Œå°†æ–°æ¶ˆæ¯åŠ å…¥å†å²
            if not boundary_detected:
                history_buffer.append(new_raw_data)

                # é™åˆ¶å†å²ç¼“å†²åŒºå¤§å°ï¼Œé¿å…è¿‡é•¿
                if len(history_buffer) > 10:
                    history_buffer = history_buffer[-8:]  # ä¿ç•™æœ€è¿‘8æ¡
                    print(f"ğŸ“š å†å²ç¼“å†²åŒºå·²æ»¡ï¼Œä¿ç•™æœ€è¿‘ {len(history_buffer)} æ¡æ¶ˆæ¯")

            # æµå¼å¤„ç†é—´éš”ï¼ˆå¯é€‰ï¼‰
            import asyncio

            await asyncio.sleep(0.1)  # æ¨¡æ‹ŸçœŸå®æ¶ˆæ¯é—´éš”

        # æ€»ç»“å’Œä¿å­˜
        print(f"\n{'='*80}")
        print(f"ğŸ‰ æµå¼æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“Š æ€»å…±å¤„ç†: {len(all_raw_data)} æ¡æ¶ˆæ¯")
        print(f"ğŸ¯ æ£€æµ‹åˆ°è¾¹ç•Œ: {len(memcells_generated)} æ¬¡")
        print(f"ğŸ’¾ ç”ŸæˆMemCell: {len(memcells_generated)} ä¸ª")
        print(f"ğŸ“š ç”ŸæˆEpisodeMemory: {len(all_episode_memories)} ä¸ª")

        if memcells_generated:
            print(f"\nğŸ“ ç”Ÿæˆçš„MemCellæ‘˜è¦:")
            for i, memcell in enumerate(memcells_generated):
                print(f"   {i+1}. {memcell.summary[:80]}...")

        if all_episode_memories:
            print(f"\nğŸ“š ç”Ÿæˆçš„EpisodeMemoryæ‘˜è¦:")
            for i, memory in enumerate(all_episode_memories):
                print(f"   {i+1}. {memory.user_id}: {memory.title[:60]}...")

        if memcells_generated or all_episode_memories:
            # è‡ªåŠ¨ä¿å­˜MemCellå’ŒEpisodeMemoryåˆ°æœ¬åœ°æ–‡ä»¶
            print(f"\nğŸ’¾ è‡ªåŠ¨ä¿å­˜æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶...")
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªMemCellçš„event_idä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†
            if memcells_generated:
                first_event_id = memcells_generated[0].event_id[:8]
            else:
                first_event_id = "no_memcell"

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            cache_filename = f"{first_event_id}_{timestamp}.json"

            saved_file = self.save_memcells_to_file(
                memcells_generated, all_episode_memories, cache_filename
            )

            if saved_file:
                print(f"âœ… æ•°æ®å·²ä¿å­˜ï¼Œä¸‹æ¬¡å¯ä½¿ç”¨ä»¥ä¸‹ä»£ç å¿«é€ŸåŠ è½½:")
                print(
                    f"   memcells, episode_memories = tester.load_memcells_from_file('{cache_filename}')"
                )

        return memcells_generated

    async def run_test(self, start_idx: int = 0, count: int = 15):
        """è¿è¡Œå®Œæ•´æµ‹è¯•æµç¨‹"""
        print("ğŸš€ å¼€å§‹è¿è¡ŒConv MemCellå’ŒEpisode Memoryæå–æµ‹è¯•")
        print("=" * 80)

        # 1. åŠ è½½æ•°æ®
        messages = self.load_928_group_data()

        # 2. è½¬æ¢ä¸ºRawData
        raw_data_list = self.convert_to_raw_data(messages, start_idx, count)

        if len(raw_data_list) < 5:
            print("âŒ è½¬æ¢åçš„æ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦5æ¡æœ‰æ•ˆæ¶ˆæ¯")
            return

        # 3. æµ‹è¯•ConvMemCellæå–
        memcell = await self.test_conv_memcell_extraction(raw_data_list)

        # 4. æµ‹è¯•EpisodeMemoryæå–
        await self.test_episode_memory_extraction(memcell)

        print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")

    async def test_cached_memcells(self, filename: str = None):
        """æµ‹è¯•åŠ è½½ç¼“å­˜çš„MemCellå¹¶è¿›è¡Œæƒ…æ™¯è®°å¿†æå–"""
        print("ğŸš€ å¼€å§‹æµ‹è¯•ç¼“å­˜çš„MemCellåŠ è½½å’Œæƒ…æ™¯è®°å¿†æå–")
        print("=" * 80)

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶åï¼Œåˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ç¼“å­˜æ–‡ä»¶
        if filename is None:
            cached_files = self.list_cached_files()
            if not cached_files:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¼“å­˜çš„MemCellæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œæµå¼æµ‹è¯•ç”ŸæˆMemCell")
                return

            # ä½¿ç”¨æœ€æ–°çš„ç¼“å­˜æ–‡ä»¶
            filename = cached_files[0]
            print(f"ğŸ”„ è‡ªåŠ¨é€‰æ‹©æœ€æ–°çš„ç¼“å­˜æ–‡ä»¶: {filename}")

        # åŠ è½½MemCellå’ŒEpisodeMemory
        memcells, episode_memories = self.load_memcells_from_file(filename)

        if not memcells:
            print("âŒ åŠ è½½MemCellå¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©º")
            return

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜çš„episode memories
        if episode_memories:
            print(f"\nâœ… å‘ç° {len(episode_memories)} ä¸ªç¼“å­˜çš„EpisodeMemoryï¼Œç›´æ¥å±•ç¤º:")
            for i, memory in enumerate(episode_memories):
                if isinstance(memory, dict):
                    user_id = memory.get('user_id', 'Unknown')
                    title = memory.get('title', 'No title')[:60]
                    print(f"   ğŸ“š #{i+1}: {user_id} - {title}...")
                else:
                    print(f"   ğŸ“š #{i+1}: {memory.user_id} - {memory.title[:60]}...")

            print(f"\nğŸ’¡ æ‰€æœ‰æ•°æ®å·²ç¼“å­˜ï¼Œæ— éœ€é‡æ–°ç”Ÿæˆï¼")
            return

        print(f"\nğŸ§ª å¼€å§‹å¯¹ {len(memcells)} ä¸ªç¼“å­˜çš„MemCellè¿›è¡Œæƒ…æ™¯è®°å¿†æå–æµ‹è¯•...")

        total_episode_memories = 0

        for i, memcell in enumerate(memcells):
            print(f"\n{'='*60}")
            print(f"ğŸ“ æµ‹è¯•MemCell #{i+1}/{len(memcells)}")
            print(f"{'='*60}")
            print(f"ğŸ†” Event ID: {memcell.event_id}")
            print(f"ğŸ“„ æ‘˜è¦: {memcell.summary[:100]}...")
            print(f"ğŸ‘¥ å‚ä¸è€…: {memcell.participants}")
            print(f"â° æ—¶é—´æˆ³: {memcell.timestamp}")

            # æ‰§è¡Œæƒ…æ™¯è®°å¿†æå–
            await self.test_episode_memory_extraction(memcell)

            # ç®€å•è®¡æ•°ï¼ˆè¿™é‡Œå¯ä»¥æ ¹æ®å®é™…è¿”å›ç»“æœè®¡æ•°ï¼‰
            if memcell.participants:
                total_episode_memories += len(memcell.participants)

        print(f"\n{'='*80}")
        print(f"ğŸ‰ ç¼“å­˜MemCellæµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“Š æµ‹è¯•äº† {len(memcells)} ä¸ªMemCell")
        print(f"ğŸ“ é¢„æœŸç”Ÿæˆçº¦ {total_episode_memories} ä¸ªæƒ…æ™¯è®°å¿†")
        print(f"ğŸ’¡ ä¼˜åŠ¿ï¼šç›´æ¥åŠ è½½MemCellï¼Œè·³è¿‡äº†å¯¹è¯è¾¹ç•Œæ£€æµ‹æ­¥éª¤ï¼Œå¤§å¤§æé«˜äº†æ•ˆç‡ï¼")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ å¯åŠ¨928ç¾¤ç»„æ•°æ®çš„Conv MemCellå’ŒEpisode Memoryæå–æµ‹è¯•")
    print("=" * 80)

    tester = TestConvMemcellEpisodeExtraction()

    print("é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. ğŸ”„ æµå¼è¾“å…¥æµ‹è¯•ï¼ˆæ¨¡æ‹ŸçœŸå®å¯¹è¯åœºæ™¯ï¼Œä¼šç”Ÿæˆå¹¶ä¿å­˜MemCellï¼‰")
    print("2. ğŸ“¦ æ‰¹é‡æµ‹è¯•ï¼ˆä¸€æ¬¡æ€§å¤„ç†å¤šæ¡æ¶ˆæ¯ï¼‰")
    print("3. ğŸ“‚ ç¼“å­˜æµ‹è¯•ï¼ˆåŠ è½½å·²ä¿å­˜çš„MemCellè¿›è¡Œæƒ…æ™¯è®°å¿†æå–ï¼‰")

    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜æ–‡ä»¶
    cached_files = tester.list_cached_files()

    if cached_files:
        print(f"\nğŸ’¡ å‘ç°ç¼“å­˜æ–‡ä»¶ï¼æ¨èå…ˆå°è¯•ç¼“å­˜æµ‹è¯•æ¨¡å¼ï¼Œé€Ÿåº¦æ›´å¿«")
        print(f"ğŸš€ è¿è¡Œç¼“å­˜æµ‹è¯•æ¨¡å¼...")
        await tester.test_cached_memcells()

        print(f"\n" + "=" * 80)
        print("ğŸ”„ é™„åŠ ï¼šè¿è¡Œæµå¼æµ‹è¯•ç”Ÿæˆæ–°çš„MemCell...")
    else:
        print(f"\nğŸ“ æ²¡æœ‰å‘ç°ç¼“å­˜æ–‡ä»¶ï¼Œè¿è¡Œæµå¼æµ‹è¯•...")

    # æµå¼æµ‹è¯•ï¼šæ¨¡æ‹ŸçœŸå®å¯¹è¯åœºæ™¯ï¼Œä¸€æ¡æ¡è¾“å…¥æ¶ˆæ¯
    memcells = await tester.run_streaming_test(
        start_idx=15, max_messages=10
    )  # å‡å°‘æ¶ˆæ¯æ•°é‡ç”¨äºå¿«é€Ÿæµ‹è¯•

    print(f"\nğŸ“ˆ æµå¼æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"   - æˆåŠŸæ£€æµ‹åˆ° {len(memcells)} ä¸ªå¯¹è¯è¾¹ç•Œ")
    print(f"   - ç”Ÿæˆäº† {len(memcells)} ä¸ªMemCell")
    print(f"   - MemCellå·²ä¿å­˜åˆ°æœ¬åœ°ï¼Œä¸‹æ¬¡å¯ç›´æ¥åŠ è½½ä½¿ç”¨")

    # å¯é€‰ï¼šä¹Ÿè¿è¡Œä¸€æ¬¡æ‰¹é‡æµ‹è¯•ä½œä¸ºå¯¹æ¯”
    print(f"\n" + "=" * 80)
    print("ğŸ” é™„åŠ ï¼šè¿è¡Œæ‰¹é‡æµ‹è¯•ä½œä¸ºå¯¹æ¯”...")
    await tester.run_test(start_idx=15, count=15)  # ä»ç¬¬15æ¡æ¶ˆæ¯å¼€å§‹ï¼Œå–15æ¡


if __name__ == "__main__":
    asyncio.run(main())
