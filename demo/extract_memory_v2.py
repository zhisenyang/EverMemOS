"""è®°å¿†æå–è„šæœ¬ V2 - ä½¿ç”¨æ–°çš„ ClusterManager + ProfileManager æ¶æ„

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºæµ‹è¯•æ–°ç»„ä»¶çš„æ•ˆæœï¼š
- ä½¿ç”¨ ClusterManager è¿›è¡Œè‡ªåŠ¨èšç±»
- ä½¿ç”¨ ProfileManager è¿›è¡Œè‡ªåŠ¨ profile æå–
- ä¸ä¾èµ–æ•°æ®åº“ï¼Œç›´æ¥è¾“å‡º JSON æ–‡ä»¶
- æ”¯æŒæ–­ç‚¹ç»­ä¼ 

ä¸»è¦æ”¹è¿›ï¼š
1. ä»£ç é‡å‡å°‘ 70%ï¼ˆä» 1400+ è¡Œåˆ° 400+ è¡Œï¼‰
2. è‡ªåŠ¨åŒ–ç¨‹åº¦æé«˜ï¼ˆèšç±»+profile å…¨è‡ªåŠ¨ï¼‰
3. æ¶æ„æ¸…æ™°ï¼ˆç»„ä»¶ç‹¬ç«‹ï¼ŒèŒè´£åˆ†ç¦»ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    python demo/extract_memory_v2.py
"""

import asyncio
import json
import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

from dotenv import load_dotenv
from rich.console import Console
from rich.progress import (
    Progress,
    SpinnerColumn,
    TextColumn,
    BarColumn,
    TaskProgressColumn,
    TimeElapsedColumn,
    TimeRemainingColumn,
    MofNCompleteColumn,
)

# ç¡®ä¿ src åŒ…å¯è¢«å‘ç°
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT / "src") not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT / "src"))
sys.path.insert(0, str(PROJECT_ROOT))

from src.memory_layer.memcell_extractor.base_memcell_extractor import RawData
from src.memory_layer.memcell_extractor.conv_memcell_extractor import (
    ConvMemCellExtractor,
    ConversationMemCellExtractRequest,
)
from src.memory_layer.llm.llm_provider import LLMProvider
from src.memory_layer.cluster_manager import (
    ClusterManager,
    ClusterManagerConfig,
    InMemoryClusterStorage,
)
from src.memory_layer.profile_manager import (
    ProfileManager,
    ProfileManagerConfig,
    ScenarioType,
    InMemoryProfileStorage,
)
from src.common_utils.datetime_utils import from_iso_format, to_iso_format

load_dotenv()

console = Console()

# ============================================================================
# é…ç½®
# ============================================================================

# è¾“å‡ºç›®å½•
OUTPUT_DIR = Path("./demo/output_v2")

# LLM é…ç½®
LLM_CONFIG = {
    "provider_type": "openai",
    "model": os.getenv("LLM_MODEL", "gpt-4"),
    "api_key": os.getenv("LLM_API_KEY"),
    "base_url": os.getenv("LLM_BASE_URL"),
    "temperature": 0.3,
    "max_tokens": 32768,
}

# èšç±»é…ç½®
CLUSTER_CONFIG = ClusterManagerConfig(
    similarity_threshold=0.65,      # ç›¸ä¼¼åº¦é˜ˆå€¼
    max_time_gap_days=7.0,          # æœ€å¤§æ—¶é—´é—´éš”ï¼ˆå¤©ï¼‰
    enable_persistence=True,
    persist_dir=str(OUTPUT_DIR / "clusters"),
    clustering_algorithm="centroid"
)

# Profile é…ç½®
PROFILE_CONFIG = ProfileManagerConfig(
    # scenario=ScenarioType.GROUP_CHAT,  # æˆ– ScenarioType.ASSISTANT
    scenario=ScenarioType.ASSISTANT,
    min_confidence=0.6,                 # ä»·å€¼åˆ¤åˆ«é˜ˆå€¼
    enable_versioning=True,
    auto_extract=True,
    batch_size=50,
    max_retries=3,
)


# ============================================================================
# æ•°æ®åŠ è½½
# ============================================================================

def load_conversations_from_json(json_path: Path) -> Dict[str, List[dict]]:
    """ä» JSON æ–‡ä»¶åŠ è½½å¯¹è¯æ•°æ®
    
    æ”¯æŒæ ¼å¼ï¼š
    1. å•ä¸ªå¯¹è¯åˆ—è¡¨: [{"speaker_id": "...", "content": "...", ...}, ...]
    2. å¤šä¸ªå¯¹è¯å­—å…¸: {"conv_1": [...], "conv_2": [...]}
    3. åŒ…å« conversation å­—æ®µ: [{"conversation": [...]}, ...]
    
    Args:
        json_path: JSON æ–‡ä»¶è·¯å¾„
    
    Returns:
        å¯¹è¯å­—å…¸: {conversation_id: [messages]}
    """
    console.print(f"\nğŸ“‚ åŠ è½½å¯¹è¯æ•°æ®: {json_path}", style="cyan")
    
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    conversations = {}
    
    conversations = {
        "conv_000": data["conversation_list"]
    }
    
    total_messages = sum(len(msgs) for msgs in conversations.values())
    console.print(f"âœ… åŠ è½½å®Œæˆ: {len(conversations)} ä¸ªå¯¹è¯, {total_messages} æ¡æ¶ˆæ¯", style="green")
    
    return conversations


def normalize_message(msg: dict) -> Optional[dict]:
    """è§„èŒƒåŒ–æ¶ˆæ¯æ ¼å¼
    
    ç¡®ä¿æ¶ˆæ¯åŒ…å«å¿…éœ€å­—æ®µï¼šspeaker_id, speaker_name, content, timestamp
    
    Returns:
        è§„èŒƒåŒ–çš„æ¶ˆæ¯å­—å…¸ï¼Œå¦‚æœæ¶ˆæ¯æ— æ•ˆåˆ™è¿”å› None
    """
    # æ£€æŸ¥è¾“å…¥ç±»å‹
    if not isinstance(msg, dict):
        return None
    
    normalized = {}
    
    # speaker_idï¼ˆæ”¯æŒå¤šç§å­—æ®µåï¼‰
    normalized["speaker_id"] = (
        msg.get("speaker_id") or 
        msg.get("sender_id") or 
        msg.get("sender") or 
        msg.get("user_id") or 
        "unknown"
    )
    
    # speaker_name
    normalized["speaker_name"] = (
        msg.get("speaker_name") or 
        msg.get("sender_name") or 
        msg.get("user_name") or 
        normalized["speaker_id"]
    )
    
    # content
    content = msg.get("content") or msg.get("text") or msg.get("message") or ""
    if not content or not str(content).strip():
        return None  # è·³è¿‡ç©ºæ¶ˆæ¯
    
    normalized["content"] = str(content).strip()
    
    # timestampï¼ˆæ”¯æŒå¤šç§å­—æ®µåï¼‰
    timestamp = (
        msg.get("timestamp") or 
        msg.get("time") or 
        msg.get("created_at") or
        msg.get("create_time")
    )
    
    if timestamp:
        if isinstance(timestamp, str):
            normalized["timestamp"] = timestamp
        elif isinstance(timestamp, (int, float)):
            from src.common_utils.datetime_utils import from_timestamp
            dt = from_timestamp(timestamp)
            normalized["timestamp"] = to_iso_format(dt)
        else:
            normalized["timestamp"] = str(timestamp)
    else:
        # ä½¿ç”¨å½“å‰æ—¶é—´
        from src.common_utils.datetime_utils import get_now_with_timezone
        normalized["timestamp"] = to_iso_format(get_now_with_timezone())
    
    # ä¿ç•™å…¶ä»–å­—æ®µ
    for key, value in msg.items():
        if key not in normalized:
            normalized[key] = value
    
    return normalized


# ============================================================================
# MemCell æå–
# ============================================================================

async def extract_memcells_from_conversation(
    conversation: List[dict],
    conv_id: str,
    memcell_extractor: ConvMemCellExtractor,
    progress: Progress = None,
    task_id: int = None,
) -> List[dict]:
    """ä»å•ä¸ªå¯¹è¯ä¸­æå– MemCells
    
    Args:
        conversation: æ¶ˆæ¯åˆ—è¡¨
        conv_id: å¯¹è¯ ID
        memcell_extractor: MemCell æå–å™¨
        progress: è¿›åº¦æ¡
        task_id: è¿›åº¦ä»»åŠ¡ ID
    
    Returns:
        MemCell å­—å…¸åˆ—è¡¨
    """
    # è§„èŒƒåŒ–æ¶ˆæ¯ï¼ˆè¿‡æ»¤æ‰ Noneï¼‰
    normalized_msgs = []
    for msg in conversation:
        normalized = normalize_message(msg)
        if normalized:  # åªä¿ç•™æœ‰æ•ˆæ¶ˆæ¯
            normalized_msgs.append(normalized)
    
    if not normalized_msgs:
        console.print(f"[red]âœ— {conv_id}: æ²¡æœ‰æœ‰æ•ˆæ¶ˆæ¯[/red]")
        return []
    
    # æå– speaker IDs
    speaker_ids = list(set(msg["speaker_id"] for msg in normalized_msgs if msg.get("speaker_id")))
    
    if not speaker_ids:
        console.print(f"[yellow]âš ï¸  {conv_id}: æ²¡æœ‰æ‰¾åˆ° speaker_idï¼Œä½¿ç”¨ 'unknown'[/yellow]")
        speaker_ids = ["unknown"]
    
    # è½¬æ¢ä¸º RawData
    raw_data_list = [
        RawData(content=msg, data_id=f"{conv_id}_msg_{i}")
        for i, msg in enumerate(normalized_msgs)
    ]
    
    memcells = []
    history_raw_data_list = []
    
    # å†å²çª—å£å¤§å°ï¼ˆå‚è€ƒåŸä»£ç çš„ history_window_sizeï¼‰
    HISTORY_WINDOW_SIZE = 200
    
    for idx, raw_data in enumerate(raw_data_list):
        # æ›´æ–°è¿›åº¦
        if progress and task_id is not None:
            progress.update(task_id, completed=idx)
        
        # ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œåˆå§‹åŒ–å†å²
        if not history_raw_data_list:
            history_raw_data_list.append(raw_data)
            continue
        
        # åˆ›å»ºæå–è¯·æ±‚
        request = ConversationMemCellExtractRequest(
            history_raw_data_list=list(history_raw_data_list),  # ä½¿ç”¨å®Œæ•´å†å²
            new_raw_data_list=[raw_data],
            user_id_list=speaker_ids,
            smart_mask_flag=True,  # å¯ç”¨æ™ºèƒ½é®ç½©ï¼ˆå‚è€ƒåŸä»£ç ï¼‰
            group_id=None,
        )
        
        # æå– MemCell
        memcell = None
        status = None
        
        for retry in range(3):
            try:
                memcell, status = await memcell_extractor.extract_memcell(request, use_semantic_extraction=True)
                break
            except Exception as e:
                if retry == 2:
                    console.print(f"[red]âœ— æå–å¤±è´¥ (conv={conv_id}, msg={idx}): {e}[/red]")
                else:
                    await asyncio.sleep(0.5)
        
        # æ ¹æ®æå–ç»“æœå¤„ç†
        if memcell:
            # æˆåŠŸæå–åˆ° MemCell
            memcell_dict = memcell.to_dict()
            memcells.append(memcell_dict)
            
            # ===== ç«‹å³ä¿å­˜ MemCellï¼ˆå‚è€ƒåŸä»£ç é€»è¾‘ï¼‰=====
            
            output_file = OUTPUT_DIR / "memcells" / f"{conv_id}_memcell_{len(memcells):03d}.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(memcell_dict, f, ensure_ascii=False, indent=2)
            
            # é‡ç½®å†å²ï¼ˆä¿ç•™å½“å‰æ¶ˆæ¯ï¼‰
            history_raw_data_list = [raw_data]
        
        elif status and status.should_wait:
            # ç­‰å¾…æ›´å¤šæ¶ˆæ¯
            history_raw_data_list.append(raw_data)
            
            # é™åˆ¶å†å²çª—å£å¤§å°ï¼ˆå‚è€ƒåŸä»£ç ï¼‰
            if len(history_raw_data_list) > HISTORY_WINDOW_SIZE:
                history_raw_data_list = history_raw_data_list[-HISTORY_WINDOW_SIZE:]
        
        else:
            # å…¶ä»–æƒ…å†µï¼šç»§ç»­ç´¯ç§¯
            history_raw_data_list.append(raw_data)
            if len(history_raw_data_list) > HISTORY_WINDOW_SIZE:
                history_raw_data_list = history_raw_data_list[-HISTORY_WINDOW_SIZE:]
    
    # ===== é‡è¦ï¼šå¤„ç†å‰©ä½™çš„å†å²æ¶ˆæ¯ï¼ˆå¼ºåˆ¶æå–ï¼‰ =====
    # å‚è€ƒåŸä»£ç é€»è¾‘ï¼Œå¾ªç¯ç»“æŸåå¦‚æœ history è¿˜æœ‰æ¶ˆæ¯ï¼Œéœ€è¦æå–
    if history_raw_data_list and len(history_raw_data_list) > 0:
        console.print(f"[cyan]â„¹ï¸  {conv_id}: å¼ºåˆ¶æå–å‰©ä½™ {len(history_raw_data_list)} æ¡æ¶ˆæ¯ä¸º MemCell[/cyan]")
        
        try:
            from src.memory_layer.types import MemCell as MemCellType, RawDataType
            import uuid
            
            # è·å–æœ€åä¸€æ¡æ¶ˆæ¯çš„æ—¶é—´æˆ³
            last_timestamp = history_raw_data_list[-1].content.get("timestamp")
            if isinstance(last_timestamp, str):
                from src.common_utils.datetime_utils import from_iso_format
                timestamp_dt = from_iso_format(last_timestamp)
            else:
                from src.common_utils.datetime_utils import get_now_with_timezone
                timestamp_dt = get_now_with_timezone()
            
            # æ„å»º original_data
            original_data = [rd.content for rd in history_raw_data_list]
            
            # åˆ›å»º MemCell
            final_memcell = MemCellType(
                event_id=str(uuid.uuid4()),
                user_id_list=speaker_ids,
                original_data=original_data,
                timestamp=timestamp_dt,
                summary=f"å¯¹è¯ç‰‡æ®µï¼ˆ{len(history_raw_data_list)} æ¡æ¶ˆæ¯ï¼‰",
                type=RawDataType.CONVERSATION,
            )
            
            final_memcell_dict = final_memcell.to_dict()
            memcells.append(final_memcell_dict)
            
            # ===== ç«‹å³ä¿å­˜æœ€åçš„ MemCell =====
            output_file = OUTPUT_DIR / "memcells" / f"{conv_id}_memcell_{len(memcells):03d}.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(final_memcell_dict, f, ensure_ascii=False, indent=2)
        
        except Exception as e:
            console.print(f"[yellow]âš ï¸  {conv_id}: å¼ºåˆ¶æå–å¤±è´¥: {e}[/yellow]")
            import traceback
            traceback.print_exc()
    
    # æ›´æ–°è¿›åº¦ä¸ºå®Œæˆ
    if progress and task_id is not None:
        progress.update(task_id, completed=len(raw_data_list))
    
    return memcells


# ============================================================================
# ä¸»æµç¨‹
# ============================================================================

async def main():
    """ä¸»å‡½æ•°"""
    
    console.print("\n" + "=" * 70, style="bold cyan")
    console.print("è®°å¿†æå–è„šæœ¬ V2 - ClusterManager + ProfileManager", style="bold cyan")
    console.print("=" * 70 + "\n", style="bold cyan")
    
    start_time = time.time()
    
    # ===== 1. å‡†å¤‡è¾“å‡ºç›®å½• =====
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    (OUTPUT_DIR / "memcells").mkdir(exist_ok=True)
    (OUTPUT_DIR / "clusters").mkdir(exist_ok=True)
    (OUTPUT_DIR / "profiles").mkdir(exist_ok=True)
    
    # ===== 2. åŠ è½½å¯¹è¯æ•°æ® =====
    # ä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤è·¯å¾„åŠ è½½
    # data_path = Path(os.getenv("CONVERSATION_DATA_PATH", "./data/conversations.json"))
    data_path = Path("/Users/admin/Documents/Projects/opensource/memsys-opensource/data/assistant_chat_zh.json")
    if not data_path.exists():
        console.print(f"[red]âœ— æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}[/red]")
        console.print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        console.print("   1. è®¾ç½®ç¯å¢ƒå˜é‡: export CONVERSATION_DATA_PATH=/path/to/data.json")
        console.print("   2. æˆ–å°†æ•°æ®æ”¾åˆ°: ./data/conversations.json")
        console.print("\næ•°æ®æ ¼å¼ç¤ºä¾‹:")
        console.print("""   {
       "conv_1": [
           {"speaker_id": "user1", "speaker_name": "Alice", "content": "Hello", "timestamp": "2024-01-01T10:00:00"},
           {"speaker_id": "user2", "speaker_name": "Bob", "content": "Hi", "timestamp": "2024-01-01T10:01:00"}
       ]
   }""")
        return
    
    conversations = load_conversations_from_json(data_path)
    
    # ===== 3. åˆå§‹åŒ–ç»„ä»¶ =====
    console.print("\nâš™ï¸  åˆå§‹åŒ–ç»„ä»¶...", style="yellow")
    
    # LLM Provider
    llm_provider = LLMProvider(**LLM_CONFIG)
    console.print("  âœ… LLM Provider åˆå§‹åŒ–å®Œæˆ", style="green")
    
    # ClusterManager
    cluster_storage = InMemoryClusterStorage(
        enable_persistence=True,
        persist_dir=OUTPUT_DIR / "clusters"
    )
    cluster_mgr = ClusterManager(config=CLUSTER_CONFIG, storage=cluster_storage)
    console.print(f"  âœ… ClusterManager åˆå§‹åŒ–å®Œæˆ (threshold={CLUSTER_CONFIG.similarity_threshold})", style="green")
    
    # ProfileManager
    profile_storage = InMemoryProfileStorage(
        enable_persistence=True,
        persist_dir=OUTPUT_DIR / "profiles",
        enable_versioning=True
    )
    profile_mgr = ProfileManager(
        llm_provider=llm_provider,
        config=PROFILE_CONFIG,
        storage=profile_storage,
        group_id="demo_extraction",
        group_name="Demo Extraction"
    )
    console.print(f"  âœ… ProfileManager åˆå§‹åŒ–å®Œæˆ (min_confidence={PROFILE_CONFIG.min_confidence})", style="green")
    
    # MemCellExtractor
    memcell_extractor = ConvMemCellExtractor(llm_provider=llm_provider)
    console.print("  âœ… MemCellExtractor åˆå§‹åŒ–å®Œæˆ", style="green")
    
    # ===== 4. è¿æ¥ç»„ä»¶ =====
    console.print("\nğŸ”— è¿æ¥ç»„ä»¶...", style="yellow")
    
    # ProfileManager â†’ ClusterManager
    profile_mgr.attach_to_cluster_manager(cluster_mgr)
    console.print("  âœ… ProfileManager å·²è¿æ¥åˆ° ClusterManager", style="green")
    
    # ClusterManager â†’ MemCellExtractor
    cluster_mgr.attach_to_extractor(memcell_extractor)
    console.print("  âœ… ClusterManager å·²è¿æ¥åˆ° MemCellExtractor", style="green")
    
    # ===== 5. å¤„ç†å¯¹è¯ =====
    console.print("\n" + "=" * 70, style="bold")
    console.print("å¼€å§‹æå– MemCells", style="bold")
    console.print("=" * 70 + "\n", style="bold")
    
    all_memcells = {}
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        MofNCompleteColumn(),
        TextColumn("â€¢"),
        TaskProgressColumn(),
        TextColumn("â€¢"),
        TimeElapsedColumn(),
        console=console,
        transient=False,
    ) as progress:
        
        main_task = progress.add_task(
            "[cyan]æ€»è¿›åº¦",
            total=len(conversations)
        )
        
        for conv_id, conversation in conversations.items():
            # åˆ›å»ºå­ä»»åŠ¡
            conv_task = progress.add_task(
                f"[yellow]{conv_id}",
                total=len(conversation)
            )
            
            # æå– MemCells
            memcells = await extract_memcells_from_conversation(
                conversation=conversation,
                conv_id=conv_id,
                memcell_extractor=memcell_extractor,
                progress=progress,
                task_id=conv_task,
            )
            
            all_memcells[conv_id] = memcells
            
            # ä¿å­˜å¯¹è¯æ±‡æ€»ï¼ˆå·²åœ¨å¾ªç¯ä¸­é€ä¸ªä¿å­˜ï¼‰
            all_memcells[conv_id] = memcells
            
            if memcells:
                progress.update(conv_task, description=f"[green]{conv_id} âœ“ ({len(memcells)} memcells)")
            else:
                progress.update(conv_task, description=f"[yellow]{conv_id} (0 memcells)")
            
            progress.update(main_task, advance=1)
    
    # ç­‰å¾…å¼‚æ­¥ profile æå–å®Œæˆ
    console.print("\nâ³ ç­‰å¾…èšç±»å’Œ Profile æå–å®Œæˆ...", style="yellow")
    await asyncio.sleep(3)
    
    # ===== 6. å¯¼å‡ºç»“æœ =====
    console.print("\n" + "=" * 70, style="bold")
    console.print("å¯¼å‡ºç»“æœ", style="bold")
    console.print("=" * 70 + "\n", style="bold")
    
    # å¯¼å‡ºæ‰€æœ‰ MemCells
    all_memcells_flat = []
    for memcells in all_memcells.values():
        all_memcells_flat.extend(memcells)
    
    if all_memcells_flat:
        with open(OUTPUT_DIR / "memcells_all.json", "w", encoding="utf-8") as f:
            json.dump(all_memcells_flat, f, ensure_ascii=False, indent=2)
        console.print(f"âœ… MemCells å·²ä¿å­˜: {OUTPUT_DIR / 'memcells_all.json'} ({len(all_memcells_flat)} ä¸ª)", style="green")
    else:
        console.print(f"[yellow]âš ï¸  æ²¡æœ‰æå–åˆ°ä»»ä½• MemCells[/yellow]")
    
    # å¯¼å‡ºèšç±»
    cluster_count = await cluster_mgr.export_clusters(OUTPUT_DIR / "clusters")
    console.print(f"âœ… èšç±»ç»“æœå·²ä¿å­˜: {OUTPUT_DIR / 'clusters'} ({cluster_count} ä¸ªç»„)", style="green")
    
    # å¯¼å‡º Profiles
    profile_count = await profile_mgr.export_profiles(
        OUTPUT_DIR / "profiles",
        include_history=True
    )
    console.print(f"âœ… Profiles å·²ä¿å­˜: {OUTPUT_DIR / 'profiles'} ({profile_count} ä¸ªç”¨æˆ·)", style="green")
    
    # ===== 7. ç»Ÿè®¡ä¿¡æ¯ =====
    console.print("\n" + "=" * 70, style="bold cyan")
    console.print("ç»Ÿè®¡ä¿¡æ¯", style="bold cyan")
    console.print("=" * 70 + "\n", style="bold cyan")
    
    # MemCell ç»Ÿè®¡
    console.print("ğŸ“ MemCell ç»Ÿè®¡:", style="bold")
    console.print(f"   - å¯¹è¯æ•°é‡: {len(conversations)}")
    console.print(f"   - æ¶ˆæ¯æ€»æ•°: {sum(len(c) for c in conversations.values())}")
    console.print(f"   - MemCell æ€»æ•°: {len(all_memcells_flat)}")
    
    # èšç±»ç»Ÿè®¡
    cluster_stats = cluster_mgr.get_stats()
    console.print("\nğŸ“Š èšç±»ç»Ÿè®¡:", style="bold")
    console.print(f"   - å¤„ç†çš„ MemCells: {cluster_stats['total_memcells']}")
    console.print(f"   - èšç±»çš„ MemCells: {cluster_stats['clustered_memcells']}")
    console.print(f"   - é›†ç¾¤æ€»æ•°: {cluster_stats['total_clusters']}")
    console.print(f"   - æ–°å»ºé›†ç¾¤: {cluster_stats['new_clusters']}")
    console.print(f"   - å¤±è´¥çš„ Embeddings: {cluster_stats['failed_embeddings']}")
    if cluster_stats['total_clusters'] > 0:
        avg_size = cluster_stats['clustered_memcells'] / cluster_stats['total_clusters']
        console.print(f"   - å¹³å‡é›†ç¾¤å¤§å°: {avg_size:.1f}")
    
    # Profile ç»Ÿè®¡
    profile_stats = profile_mgr.get_stats()
    console.print("\nğŸ‘¤ Profile ç»Ÿè®¡:", style="bold")
    console.print(f"   - å¤„ç†çš„ MemCells: {profile_stats['total_memcells']}")
    console.print(f"   - é«˜ä»·å€¼ MemCells: {profile_stats['high_value_memcells']}")
    console.print(f"   - Profile æå–æ¬¡æ•°: {profile_stats['profile_extractions']}")
    console.print(f"   - å¤±è´¥çš„æå–: {profile_stats['failed_extractions']}")
    console.print(f"   - ç›‘æ§çš„é›†ç¾¤: {profile_stats['watched_clusters']}/{profile_stats['total_clusters']}")
    if profile_stats['total_memcells'] > 0:
        high_value_rate = profile_stats['high_value_memcells'] / profile_stats['total_memcells']
        console.print(f"   - é«˜ä»·å€¼æ¯”ç‡: {high_value_rate:.1%}")
    
    # ç”¨æˆ· Profiles
    all_profiles = await profile_mgr.get_all_profiles()
    if all_profiles:
        console.print(f"\nğŸ‘¥ æå–çš„ç”¨æˆ· Profiles ({len(all_profiles)} ä¸ª):", style="bold")
        for user_id, profile in list(all_profiles.items())[:5]:  # åªæ˜¾ç¤ºå‰ 5 ä¸ª
            console.print(f"\n   ğŸ“Œ {user_id}:")
            if hasattr(profile, 'user_name'):
                console.print(f"      å§“å: {profile.user_name}")
            if hasattr(profile, 'hard_skills') and profile.hard_skills:
                skills = [s.get('value') for s in profile.hard_skills[:3]]
                console.print(f"      æŠ€èƒ½: {', '.join(skills)}")
            if hasattr(profile, 'work_responsibility') and profile.work_responsibility:
                resp = [r.get('value') for r in profile.work_responsibility[:2]]
                console.print(f"      èŒè´£: {', '.join(resp)}")
        
        if len(all_profiles) > 5:
            console.print(f"\n   ... è¿˜æœ‰ {len(all_profiles) - 5} ä¸ªç”¨æˆ·")
    
    # è€—æ—¶
    elapsed = time.time() - start_time
    console.print(f"\nâ±ï¸  æ€»è€—æ—¶: {elapsed:.1f} ç§’", style="bold yellow")
    
    # ===== 8. è¾“å‡ºç›®å½•ç»“æ„ =====
    console.print("\n" + "=" * 70, style="bold cyan")
    console.print("è¾“å‡ºæ–‡ä»¶", style="bold cyan")
    console.print("=" * 70 + "\n", style="bold cyan")
    
    console.print(f"ğŸ“ {OUTPUT_DIR}/")
    console.print("â”œâ”€â”€ memcells/")
    console.print(f"â”‚   â”œâ”€â”€ conv_000.json (å•ä¸ªå¯¹è¯çš„ MemCells)")
    console.print(f"â”‚   â””â”€â”€ ... ({len(conversations)} ä¸ªæ–‡ä»¶)")
    console.print("â”œâ”€â”€ memcells_all.json (æ‰€æœ‰ MemCells)")
    console.print("â”œâ”€â”€ clusters/")
    console.print("â”‚   â”œâ”€â”€ cluster_state_demo_extraction.json (èšç±»çŠ¶æ€)")
    console.print("â”‚   â””â”€â”€ cluster_map_demo_extraction.json (èšç±»æ˜ å°„)")
    console.print("â””â”€â”€ profiles/")
    console.print(f"    â”œâ”€â”€ profile_user1.json (ç”¨æˆ· Profile)")
    console.print(f"    â”œâ”€â”€ profile_user2.json")
    console.print(f"    â”œâ”€â”€ ... ({profile_count} ä¸ªç”¨æˆ·)")
    console.print("    â””â”€â”€ history/ (Profile å†å²ç‰ˆæœ¬)")
    
    console.print("\n" + "=" * 70, style="bold green")
    console.print("âœ… æå–å®Œæˆï¼", style="bold green")
    console.print("=" * 70 + "\n", style="bold green")


if __name__ == "__main__":
    asyncio.run(main())

